---
title: "Guide to processing of geo-spatial covariates to be used in poverty modelling - an example of Bangladesh"
author: "Ida Brzezinska"
format: html
editor: visual
---

# Section A: Geo-spatial

## 1. Introduction

Nick's introduction here

## 2. Theory - key concepts in Geo-spatial analysis

Spatial data has a slightly different structure to standard data frames that you may have worked with in the past, say a household survey, in that (as the name gives away) it is indexed to a specific geographical location on Earth. It still conatins data values, but a lot of the attributes of these spatial objects are used to describe its geographical location, so that we can position our data values adequately on the surface of the Earth (aside: while our analysis will be confined to objects on Earth, GIS analytics can very well be applied to other objects in Space, such as [NASA's Interactive GIS map of Mars](https://astrogeology.usgs.gov/facilities/mrctr/mars-online-map)).

Before digging into the structure and technicalities of how spatial objects are organised - let us consider briefly the most common sources of geo-spatial data.

### 2.1. Geo-spatial data sources

#### Traditional surveys

Recall that geo-spatial data is simply a set of data values that are indexed to a geographical location on Earth. In that sense, traditional census or surveys are sources of geo-spatial data as long as they contain information on administrative units, GPS location, or any other geographical identifiers. Data coming from traditional surveys can even be more precise, for instance if we are interesetd in measuring a building and its properties.

#### Remote sensing

Increasingly, **remote sensing** data collection is turning out to be a more efficient method than surveys. This includes satellite imagery and aircraft sensors that orbit the Earth and collect data continuously, at a high spatial resolution, and globally, including places that would be hard to reach with a survey (say the middle of the ocean or conflict-affected areas). In fact, due to the advantages of remote sensing data collection - space is becoming a crowded place, and increasingly more so in the last couple of years. Figure X below shows the time trend of the annual number of objects launched into space, which explodes upwards after around 2015. As of 2022, there were 6,905 active satellites in space. In this workflow, we will be working exclusively with remote sensing data, but let us briefly consider other sources of geo-spatial information.

![](images/Objects%20launched%20into%20space.png){width="573"}

Source: [Our World in Data](https://ourworldindata.org/space-exploration-satellites)

#### Crowdsourcing

For all the growing interest in fancy remote sensing data collection, it is worth acknowledging that highly valuable geo-spatial information often comes from humans on the ground! Crowdsourcing geo-spatial data is often done via informal social networks and does not require any formal training in geo-spatial technologies. Perhaps one of the most notable examples is [Open Street Map](https://www.openstreetmap.org/about) (OSM), a community of mappers with local knowledge that produce open source maps. The [Humanitarian team at OSM](https://www.hotosm.org/) produces community-developed maps in areas such as Disasters & Climate Resilience or Public Health - [for example](https://www.hotosm.org/projects/integrating-openstreetmap-data-into-caribbean-disaster-response-efforts-geocris/), OSM is working with the World Bank and the Caribbean Disaster Emergency Management Agency (CDEMA) to integrate their maps into official disaster risk response.

#### Cell phone data

Basic services provided by cell phone operators are routed by satellites, providing location information at various levels of precision (from GPS to cell phone tower), together with Call Detail Records (CDR). [Flowminder](https://www.flowminder.org/about-us) is an example of an organisation that leverages mobile operator data in development projects, for instance tracking population movements post the 2015 Nepal Earthquake.

#### Online data

Online data is broad and includes all data shared online purposefully, including Wikipedia, social media, online articles etc. Location and mobility tracking via social media can be another source of geographical information. App-based mobile phone location data is actually often of higher spatial resolution than that coming from cell phone data operators and is increasingly being used in mobility studies. In fact, we will be using high-resolution population density estimates from Meta (previously Facebook) in our poverty modelling exercise.

### 2.2. Data structures

Here I want to introduce the two most common spatial data types, which we will be working with in our poverty mapping exercise, together with their attributes:

1.  **Raster data** - any gridded (or pixelated) data where each pixel represents a specific geographical location. The value can be continuous (e.g. temperature) or categorical (e.g. land use). If pixels sound familiar, it's because they are - in fact, this is how every digital image is represented. The only difference is that a raster additionally includes spatial information that connects data from the image to a particular location. The location is defined by the following attributes (these are important attributes to inspect when you first open your raster):

-   Extent: the maximum and minimum values of longitute and latitude that define the boundaries of our spatial structure.

-   Cell size (spatial resoluton or size of each pixel)

-   The number of rows and columns

-   Coordinate Reference System (CRS)

    To illustrate this concept, below is a raster image showing the elevation of Harvard Forest. Each pixel has values of elevation assigned, which range from 0-9. Here, the spatial resolution is 1m x 1m, which means each pixel has an area of 1m by 1m (this is really granular!).

    ![](images/Raster%20image.png){width="574"}

Source: [National Ecological Observatory Network](https://www.neonscience.org/)

Mention file extensions of raster data?

2.  **Vector data** - represents structures on the Earth's surface that are defined by discrete locations (x,y) called vertices. Depending on how the vertices (x,y) are oragnised, we can divide vector data types into: **points, lines, and polygons**. You could think of: locations of hospitals, road networks, administrative boundaries.

![](images/Geometry%20vector.png){width="568"}

Source: [National Ecological Observatory Network](https://www.neonscience.org/)

To illustrate this concept, below is a vector data set with lines showing the road network in Ghana, developed through Open Street Maps Ghana, downloadable via the Humanitarian Data Exchange website. Each line is determined by its vertices (think of them as the (x,y) points shown in the image above) and indexed geographically in space.

![](images/Ghana%20road%20network.png){width="648"}

Source: [Humanitarian Data Exchange](https://data.humdata.org/dataset/hotosm_gha_roads)

Vector data comes in many formats, but we will be working with the (very common) Shapefile format, which has a .shp extension. More specifically, we will download a shapefile containing multipolygons that define adminsitrative boundaries of upazilas (admin level 3) in Bangladesh. A shapefile stores the coordinates of vertices, as well as other metadata:

-   Extent

-   Object type - whether the shapefile contains points, lines, or polygons.

-   Coordinate Referenec System (CRS)

-   Other attributes - e.g. in our case the name of the upazila, its administrative code, area covered etc.

Could have a short quiz here showing different images and asking the audience whether this is a raster or a vector dataset.

### 2.3. Layering geo-spatial data sets

Now that you are familiar with the basic types of geo-spatial datasets, we can start thinking about performing some simple mapping. Typically, rather than viewing each layer of data (such as your road network, elevation, temperature etc.) individually, it is valuable to overlay them on top of each other, so that we can view multiple geo-spatial layers at the same time. The diagram in Figure XX below demonstrates this concept: while we can inspect data on streets, buildings, and vegetation individually, a much more interesting way to look at these layers is by viewing the simultaneously, as in the "Integrated data" portion of the diagram at the very bottom.

![](images/Data%20layers.jpg){width="555"}

Source: [National Geographic](https://education.nationalgeographic.org/resource/geographic-information-system-gis/)

::: callout-caution
## Caution

Make sure that the CRS is the same for all of your objects before layering. The most standard CRS is the World Geodetic System 1984 (WGS 84), but you may encounter other ones when working with spatial data for specific regions of the world.
:::

Now, let's see an example of visualising multiple raster layers from our project work under [Data & Evidence to End Extreme Poverty (DEEP)](https://povertyevidence.org/). In this case, we wanted to map the spatial distribution of climatic risks in Nigeria, looking at droughts and floods. Figure XX below shows the worst drought (defined as Standardized Precipitation Evapotranspiration Index or SPEI below -1.5) and all flooded areas in the period 2010-2020 in Nigeria, on top of an Open Street Map background. Drought is captured by a continuous variable for a range of values of SPEI, while flood is a categorical variable (i.e. flood or no flood), with flooded areas shown in blue. We can see that the extent of these layers differs, i.e. drought is only defined within Nigeria (including bordering grid cells), while flood data extends beyond the borders of Nigeria and considers an entire river system, which is not necessarily bound by national borders.

![Rasters showing all floods and the worst droughts in Nigeria between 2010-2020](images/Nigeria%20flood%20drought%20.png)

The two layers (drought and flood) also have different spatial resolutions. Here, drought data is of a lower spatial resolution, i.e. it comes up as big pixels of around 0.5 degrees (or \~30km), while flood data is extremely high resolution, with each pixel the size of \~250m x 250m, coming from the NASA MODIS satellite. Figure XX below shows a zoom into two grid cells of drought data, which contain numerous grid cells with flood data. The higher the spatial resolution, the smaller your grid cells!

![Zoom into pixels showing floods and droughts in Nigeria](images/Pixel%20zoom%20in%20.png)

### 2.4. Raster manipulation for poverty modelling

The previous section introduced the concept of working with multiple layers of geo-spatial information. In our example, the two layers, despite being displayed on top of each other, had very different attributes: spatial resolution, cell sizes, extent . However, there are cases, as in the poverty modelling exercise we are about to do, where we want to "harmonise" our raster objects, i.e. make sure all the attributes (CRS, extent, spatial resolution, cell size) are the same when rasters are overlaid on top of each other.

Let's consider our problem at hand again: **We want to compute zonal poverty statistics at administrative level 3 (upazila) level in Bangladesh.** We will do so by using statistical modelling and a number of remote sensed covariates as our predictors. For this, we need some basic statistics (mean, min, max, standard deviation, count etc.) that describe our geo-spatial information for each upazila. For example, what is the mean Travel Time to Healthcare Facilities (in minutes) in the upazila of Abador? Or, what is the median nightlights intensity in that upazila? While R is smart enough to compute those statistics for us automatically, we need to provide it with a nicely harmonised set of rasters. We will use a "base layer", which contains all the attributes we are interested in, and harmonise all other remote sensing covariates to our base layer. That is: we will match the CRS, extent, spatial resolution, cell size of the base layer.

With that in mind, I will introduce a few ways in which we will manipulate spatial data. This is a useful skill to have as we will soon discover that raw open source data can be a little messy and you may need to implement some of these steps to make sense of your data before any meaningful analysis.

1.  **Cropping -** changing the extent of our spatial objects, i.e. the maximum and minimum values of longitude and latitude that define the object, to that of the base layer.
2.  **Resampling** - changing the spatial resolution so that it matches that of the base layer.

::: callout-caution
## Caution

There are many algorithms that can be used for changing the spatial resolution of a raster.
:::

3.  **Recoding missing values** - (only if appropriate) changing missing values to a specified value.

::: callout-caution
## Caution

A note of caution on missing values in geo-spatial data. As with every data type, the treatment of missing values can be a source of philosophical discussions and should always be determined depending on the context and the specific problem at hand. The user should always ask themselves: can a missing value be interpreted as a zero or do we simply not have enough information to conclude? If it is a zero, missing values should be recoded accordingly.
:::

4.  **Masking** - cutting the exact "shape" of a raster layer. This is different from cropping, which would leave us with a chunky box that contains Bangladesh, but also some areas between the maximum and minimum values that fall outside of Bangladesh. We can use the mask function to examine only the country boundaries.

These concepts may seem a little abstract for now, so let us consider visually what each of these processes will entail. Let's take the example of processing geo-spatial data on nightlights intensity for Bangladesh - a process we will be implementing in Step 5 of Section 3. Night lights intensity has been widely used in literature as a proxy for income and will be one of our predictors of poverty. Figure XX shows a TIFF file with the aerial shot of nightlights intensity in South-East Asia as seen from space. We can see that urban areas and areas with higher density of economic activity appear more luminous. We will use the functions described above to manipulate this TIFF file and transform it into a raster layer for Bangladesh with codified values of radiance per pixel (this is a measure of nightlights intensity).

![](images/Nightlights%20data%20-01.png)

Figure XX below shows the processing of data on nightlights intensity. The left hand side is what you will see if you simply load the above TIFF file into your R environment, turn it into a raster, and plot - in other words, not much. Although it is a little difficult to see, the original raster is showing values of nightlights intensity for the entire South East Asia region at the orginal spatial resolution of around \~450m. First, we are interested in analysing just Bangladesh, rather than the entirely of South East Asia (not least because TIFF files can be quite heavy and maintaining unnecessarily large raster objects slows down a lot of the computation). We will "crop" our raster object to the Bangladesh base layer, i.e. we will change the extent to that of Bangladesh. Now, our raster object changed dimensions. It is defined by the maximum and minimum values of longitude and latitude in Bangladesh.

The next step in the process is to resample the raster, i.e. change the spatial resolution to \~100m to match that of our base layer. Going from a lower to a higher spatial resolution is called disaggregation. If we zoomed into the image under "resample", we would see more smaller pixels appear than previously. Finally, we want to view the "shape" fo Bangladesh, rather than a rectangular box bound by its extent. For this purpose, we "mask" our raster layer with nightlights to the base layer - and we finally achieve a nicely formatted raster that resembles Bangladesh!

![](images/Nightlights%20data%20processing.png)

See a zoomed in version of our final raster with nightlights in Figure XX below. We can see urban areas of Dhaka and Chattogram in lighter shades of blue and yellow - indicating higher luminosity.

![](images/nightlight%20zoom.png)

Note that the nightlights raster did not contain missing values and any location with no radiance was coded as having a value of zero nightlights intensity. There are cases, however, where we should be more careful about the interpretation of missing values vs. zeros. In our next example, we will go through the processing of high-resolution demographic maps from Meta, specifically the population density of youth aged 15-24 - a process we will be implementing in Step 4 of Section 3. The left hand side of Figure XX below shows the result from simply plotting the raster from the original TIFF file. We can see a few colour-coded values of population density, but most of the raster is empty (NAs shown in white). Here, the user should consider: are the values missing because there are no people in this location? Or is it because we haven't collected data on those locations? In our case, the documentation tells us that missing values are equivalent to there being no people aged 15-24. After recoding NA values as 0s, we see that the raster layer is now populated with values (zeros shown in grey).

As in the example of nightlights, we want to crop our raster so that it has the extent of Bangladesh. Afterwards, we will change the spatial resolution to \~100m. Note that the population density data is originally of a higher spatial resolution (of around \~30m), so in this case we are resampling to a coarser grid. This process is called aggregation. Since we are deploying the "sum" algorithm, we can observe that the legend beside the plot has changed - we now have larger density of people per pixel (since our pixels just got bigger as a result of aggregation). The final step is to mask our raster with demographic data to the base layer - and we end up with a nice shape of Bangladesh.

![](images/FB%20data%20processing.png)

And a higher resolution image of our final result below:

![](images/Population%20density%20youth-02.png)

These are exactly the processing steps that we will be carrying out in our next session, although they will all be automated with a single function for ease of application.

### 2.5. Spatial Data in R

Given that our entire workflow will be carried out in R to make it accessible, open source, and user-friendly - we will introduce some common spatial objects in R. There are numerous packages that allow you to work with spatial data. In fact, packages are very often retired and new ones are created to replace them. We will be relying mostly on:

1.  The `sp` and `sf` packages for vector data
2.  The `raster` package for raster data
3.  The `rgdal` package for manipulation of geo-spatial data using the GDAL library.

#### 2.5.1. `sp` package

Recently spatial data in R has been standardised using the base package `sp`. Although a better version of this package exists, called `sf` , it is useful to understand basic data structures under `sp`. Let's have a look at the spatial data classes by running the chunk below:

```{r}
library(sp)
getClass("Spatial")
```

A basic `sp` object will have two "slots": a bounding box `bbox` containing a matrix of longitude and latitude values (or, using the language we introduced earlier, the extent of an object) and `proj4string`, which is the CRS. These parameters will help us locate our object in space. The basis of all the spatial objects is a matrix or data frame with latitude and longitude values - this is what we need to make our existing objects in R "spatial". From the output above, we can also see that objects build on each other. This is illustrated in Figure XX below. For example, taking our matrix or data frame with latitude and longitude, we can create a `SpatialPoints` object, which would simply be a collection of spatial points. We can build on this and create a `SpatialPointsDataFram`e by adding a data frame with attributes associated with these points. The same can be done for lines and polygons.

![](images/spatial%20objects%20in%20R.png)

#### 2.5.2 `sf` package

![](images/sf%20objects-01.png)

Source: CRAN project, sf vignette

### 2.6 Homework

Potential homework: Visualising Spatial Data in R at DataCamp

OR: Spatial Objects in R

## 3. Applying this

### Data sources - Bangladesh

We will be working with the following data sets:

1.  **Base layer**: WorldPop Administrative Level 0 mastergrid base layer for Bangladesh at \~100m spatial resolution. This mastergrid defines the administrative boundaries of the country, to which we will be harmonising all other geo-spatial datasets, i.e. matching the spatial resolution, CRS (geographical projection), extent, and shape.

2.  **Shape file**: Subnational Administrative Boundaries for Bangladesh from the Humanitarian Data Exchange. This file contains the administrative boundaries of the zones for which we will be estimating poverty. In our case, this is done at administrative level 3 (upazila) in Bangladesh.

3.  **Malaria Atlas data on accessibilit**y, including: travel time to cities and healthcare facilities.

4.  **Demographic maps from Meta** at \~30m spatial resolution showing population density of different demographic groups (men, women, youth, elderly etc.).

5.  **Nightlights data** at \~450m spatial resolution with almost global coverage.

6.  **World Pop** Pre-harmonised geo-spatial datasets: available for all countries. The datasets includes information on topography, slope, Open Street Map distance to closest road, waterway, and various land cover classes. Note that this data has already been harmonised to our base layer and hence will not require any processing in this script.

### Base layers

| Geo-spatial file name             | Description                                                          | Year | Link to download                                                                                                               |
|:--------------|:--------------|:--------------|:--------------------------|
| bgd_level0_100m_2000_2020.tif     | WorldPop Administrative Level 0 mastergrid base layer for Bangladesh | 2020 | [World Pop Hub - National boundaries](https://www.worldpop.org/geodata/summary?id=24282)                                       |
| bgd_admbnda_adm3_bbs_20201113.shp | Administrative Level 3 (Upazila) Units in Bangladesh                 | 2015 | [Bangladesh - Subnational Administrative Boundaries - Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-bgd) |

### Geo-spatial data sets to be harmonised

|                                                                             |                                                                              |      |                                                                                                                                                                                                                                                                                                  |
|--------------|--------------|:-------------|-------------------------------|
| **Geo-spatial file name**                                                   | Description                                                                  | Year | Link to download                                                                                                                                                                                                                                                                                 |
| SVDNB_npp_20150101-20151231_75N060E_vcm-orm_v10_c201701311200.avg_rade9.tif | VIIRS night-time lights (global)                                             | 2015 | [Earth Observation Group](https://eogdata.mines.edu/products/vnl/#v1)                                                                                                                                                                                                                            |
| 2015_accessibility_to_cities_v1.0.tif                                       | MAP travel time to high-density urban centres (global)                       | 2015 | [Malaria Atlas - Accessibility to Cities](https://data.malariaatlas.org/maps?layers=Accessibility:201501_Global_Travel_Time_to_Cities,Malaria:202206_Global_Pf_Parasite_Rate)                                                                                                                    |
| 2020_motorized_travel_time_to_healthcare.tif                                | MAP motorised only travel time to healthcare facilities (global)             | 2019 | [Malaria Atlas - Motorised Time Travel to Healthcare](https://data.malariaatlas.org/maps?layers=Accessibility:202001_Global_Motorized_Travel_Time_to_Healthcare,Malaria:202206_Global_Pf_Parasite_Rate&extent=-11815912.856289707,-6356003.33856192,28286163.259866484,14615055.359158086)       |
| 2020_walking_only_travel_time_to_healthcare.tif                             | MAP walking only travel time to healthcare facilities (global)               | 2019 | [Malaria Atlas - Walking Only Time Travel to Healthcare](https://data.malariaatlas.org/maps?layers=Accessibility:202001_Global_Walking_Only_Travel_Time_To_Healthcare,Malaria:202206_Global_Pf_Parasite_Rate&extent=-11815912.856289707,-6356003.33856192,28286163.259866484,14615055.359158086) |
| bgd_general_2020.tif                                                        | Meta (Facebook) Population density -- Overall; BGD                           | 2020 | [Humanitarian Data Exchange - Demographic Maps from Meta](https://data.humdata.org/dataset/bangladesh-high-resolution-population-density-maps-demographic-estimates)                                                                                                                             |
| bgd_men_2020.tif                                                            | Meta (Facebook) Population density -- Men; BGD                               | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_elderly_60_plus_2020.tif                                                | Meta (Facebook) Population density -- Elderly (aged 60+); BGD                | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_women_of_reproductive_age_15_49_2020.tif                                | Meta (Facebook) Population density -- Women of reproductive age (15-49); BGD | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_women_2020.tif                                                          | Meta (Facebook) Population density -- Women; BGD                             | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_youth_15_24_2020.tif                                                    | Meta (Facebook) Population density -- Youths aged 15-24; BGD for 2020        | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_children_under_five_2020.tif                                            | Meta (Facebook) Population density -- Children under 5; BGD                  | 2020 |                                                                                                                                                                                                                                                                                                  |

### WorldPop harmonised geo-spatial data sets

|                                           |                                                                         |           |                                                                |
|-----------------|---------------------|-----------------|------------------|
| **Geo-spatial File Name**                 | **Description**                                                         | **Year**  | **Link to Download**                                           |
| bgd_srtm_topo_100m.tif                    | SRTM topography in BGD                                                  | 2000      | [World Pop](https://www.worldpop.org/project/categories?id=14) |
| bgd_srtm_slope_100m.tif                   | SRTM slope (derivative of topography) in BGD                            | 2000      |                                                                |
| bgd_esaccilc_dst040_100m_2014.tif         | Distance to ESA-CCI-LC woody-tree area edges in BGD                     | 2014      |                                                                |
| bgd_esaccilc_dst140_100m_2014.tif         | Distance to ESA-CCI-LC herbaceous area edges in BGD                     | 2014      |                                                                |
| bgd_osm_dst_road_100m_2016.tif            | Distance to OSM major roads in BGD                                      | 2016      |                                                                |
| bgd_esaccilc_dst150_100m_2014.tif         | Distance to ESA-CCI-LC sparse vegetation area edges in BGD              | 2014      |                                                                |
| bgd_osm_dst_roadintersec_100m_2016.tif    | Distance to OSM major road intersections in BGD                         | 2016      |                                                                |
| bgd_esaccilc_dst160_100m_2014.tif         | Distance to ESA-CCI-LC aquatic vegetation area edges in BGD             | 2014      |                                                                |
| bgd_osm_dst_waterway_100m_2016.tif        | Distance to OSM waterways in BGD                                        | 2016      |                                                                |
| bgd_esaccilc_dst190_100m_2014.tif         | Distance to ESA-CCI-LC artificial surface edges in BGD                  | 2014      |                                                                |
| bgd_esaccilc_dst011_100m_2014.tif         | Distance to ESA-CCI-LC cultivated area edges in BGD                     | 2014      |                                                                |
| bgd_esaccilc_dst200_100m_2014.tif         | Distance to ESA-CCI-LC bare area edges in BGD                           | 2014      |                                                                |
| bgd_esaccilc_dst_water_100m_2000_2012.tif | Distance to ESA-CCI-LC inland water in BGD                              | 2012      |                                                                |
| bgd_wdpa_dst_cat1_100m_2014.tif           | Distance to IUCN strict nature reserve and wilderness area edges in BGD | 2014      |                                                                |
| bgd_esaccilc_dst130_100m_2014.tif         | Distance to ESA-CCI-LC shrub area edges in BGD                          | 2014      |                                                                |
| bgd_dst_coastline_100m_2000_2020.tif      | Distance to open water coastline in BGD                                 | 2000-2020 |                                                                |

### Libraries

Throughout this workflow, we will be using functions from the packages shown in the chunk below. Most of them allow for manipulation of spatial objects in R, others are used to enhance our data visualisations - such as nice colour schemes for maps. All the below packages need to be installed and loaded in order for the workflow to run smoothly. If you don't already have some of the below packages installed, you can do so by running: install.packages("your.package.name"). After that, you will be able to load the package using library("the.package.you.just.installed"). See below the dependencies we will need for this workflow:

```{r libraries}
#| echo: true
#| output: false

library("tiff")           # opening geoTIFF files
library("raster")         # raster manipulation
library("sf")             # working with vector data
library("ggplot2")        # plots
library("RColorBrewer")   # funky graph colors 
library("haven")          # opening stata files
library("gsubfn")         # string operations
library("viridis")        # colour palette for data visualisations
library("rgdal")          # RGDAL functions
library("sp")             # spatial objects in R
library("plyr")           # Data wrangling
library("dplyr")          # Data wrangling
library("readr")          # read rectangular data
```

### Step 1 - Load all data sets

Now we are equipped with the tools to start the processing of our geo-spatial datasets. We start by specifying the directory we will be working from and loading all of the data sets described above into our environment and saving them as raster objects. In this example, the geo-spatial files are organised into the following folders:

1.  Base layer
2.  Shape file with administrative level 3 boundaries
3.  Malaria Atlas accessibility datasets
4.  Demographic Maps from Meta
5.  Nightlights Data
6.  Pre-harmonised World Pop datasets

We would recommend this structure as it allows us to automatically pull all the files from each folder based on their \*tif extension and makes the below workflow easy to follow. The user should select their corresponding working directory, based on where the geo-spatial data was saved.

```{r load layers}
# Set working directory - this is the base folder where we keep all the sub-folders with geo-spatial data organised by source. 
setwd("C:/Users/idabr/OneDrive - Oxford Policy Management Limited/EMDI SAE/Geo-spatial Bangladesh data/")

# 1. Base layer #

# Load the WordPop Administrative Level 0 mastergrid base layer for Bangladesh 
base.layer <- 'Base layers/bgd_level0_100m_2000_2020.tif'
base.layer.raster=raster(base.layer)

# 2. Shapefile with boundaries of zones #

# Load the Shapefile with administrative level 3 (upazila in Bangladesh)
shapefile.zonal <- readOGR("Base layers/admin 3 level/bgd_admbnda_adm3_bbs_20201113.shp")

# Load the shapefile in a format that's nicer for plotting 
shapefile.zone.plot <- st_read("Base layers/admin 3 level/bgd_admbnda_adm3_bbs_20201113.shp")

# 3. Malaria Atlas accessibility datasets #

#Make a list of all TIFF files from the Malaria Atlas Project and import those into a list 
matlas.list <- list.files(path="Travel time - Malaria Atlas Project", pattern =".tiff", full.names=TRUE)

# Turn all files into a raster and make a list of rasters
matlas.rasters <- lapply(matlas.list, raster)

# 4. Demographic maps from Meta #

# Pull all TIFF files from Meta with demographic maps
fb.list <- list.files(path="Demographic maps Facebook/", pattern =".tif", full.names=TRUE)

# Turn all files into a raster and make a list of rasters
fb.rasters <- lapply(fb.list, raster)

# 5. Nightlights Data #

# Import geoTIFF file on nightlights intensity
nightlights <- 'Nightlights data/SVDNB_npp_20150101-20151231_75N060E_vcm-orm_v10_c201701311200.avg_rade9.tif'

# Turn into a raster 
nightlights.raster = raster(nightlights)

# 6. Pre-harmonised World Pop datasets #

# Make a list of all TIFF files from WorldPop and import those into a list 
worldpop.list <- list.files(path="World Pop Harmonised Datasets", pattern =".tif", full.names=TRUE)

# Turn all files into a raster and make a list of rasters
worldpop.rasters <- lapply(worldpop.list, raster)


```

#### Check the attributes of the base layer

As we will be harmonising all other datasets to our base layer, it is important to understand its attributes. Simply typing the name of our base layer raster object in the console will provide information on: class, dimensions, resolution, extent, crs, source, and names. At the end of the workflow, all of our geo-spatial covariates will have the same spatial resolution, CRS, extent, and shape as our base layer.

```{r plot base raster}
# Check attributes associated with the base layer 
base.layer.raster

# Plot raster
plot(base.layer.raster, box=F, axes=F,legend=F, main = "Bangladesh base layer")
```

The output is telling us that our object of interest is a Raster Layer, with the following characteristics:

-   7272 rows, 5596 columns, and 40694112 cells altogether.

-   \~ 100m spatial resolution. This defines the size of each cell in the raster.

-   The maximum and minimum values of longitude and latitude which define Bangladesh.

-   The WGS 1984 datum (EPSG: 4326) geographical projection.

-   It came from the GeoTIFF file named "bgd_level0_100m_2000_2020.tif" in our working directory.

-   The naming convention is the same as the original GeoTIFF file (in this case bgd_level0_100m_2000_2020).

We also produced our first map of Bangladesh! This is the raster layer we will be harmonising all our other data to.

#### Inspect the attributes of the shapefile with administrative level 3

Now that we have a raster file defining the national boundaries of Bangladesh, we are interested to know the boundaries of the administrative zones that we will estimate poverty for. In our case, this is administrative level 3, or upazila, in Bangladesh. Let's have a look at the shapefile that will outline those.

As before, we will start by simply typing the name of our spatial object into the console. This will provide information on: geometry, dimensions, extent, CRS, as well as give us a preview into the features.

Plotting the shapefile will show us the upazilas (zones) for which we will be estimating poverty.

```{r}
# See metadata associated with the shapefile
shapefile.zone.plot

# Plot the shape file - this shows the zones for which we will estimate poverty
ggplot() + 
  geom_sf(data = shapefile.zone.plot, size = 3, color = "black", fill = "cyan1") + 
  ggtitle("Administrative Level 3 Bangladesh") + 
  coord_sf() + theme_minimal()
```

The output gives us the following information about the shape file:

-   It has 544 features (upazilas) and 16 fields with information defining the features.

-   The geometry type is multipolygon. Each multipolygon is a collection of spatial points that define an upazila.

-   Bounding box shows the extent, i.e. maximum and minimum values of longitude and latitude that define Bangladesh.

-   As in the case of our base layer, it uses the WGS 1984 datum (EPSG: 4326) geographical projection.

-   A preview of the first 10 features tells us that for each multipolygon we have information on: administrative codes for the upazila, English name of the upazila, area covered by the shape, and codes as well as names for other administrative levels.

With our base layers defined, it's time to start the processing of geo-spatial data.

### Step 2 - write functions for automated processing of geo-spatial covariates

In this step, we will provide two functions that will automate the processing of geo-spatial covariates.

Function 1 can be applied to the Malaria Atlas accessibility data and Nightlights data. It automatically executes the following steps:

1.  Crop your raster to the base layer so that they have the same extent
2.  Change the spatial resolution of your raster to match that of the base layer using the nearest neighbor interpolation algorithm.
3.  If appropriate, recode missing values to a specified value.
4.  Mask the raster so that it has the same shape as your base layer.

The function requires the following inputs:

-   aux.raster - this is the raster that you are trying to transform/ harmonise to the base raster layer.

-   base.raster - your base raster layer that has all the desired attributes. This is the layer we will be harmonising to.

-   label - the name that you wish to assign to the transformed raster.

-   value - (if appropriate) the value to which you want to recode NA (missing) values to.

This process will output your transformed raster, ready to be used in the estimation of zonal statistics.

```{r function ngb}
# Function for automating the processing of geo-spatial covariates for use in poverty modelling
geo_process <- function(aux.raster, base.raster, label, value) {

    # 1. Crop to the base layer so they have the same extent
    r <- crop(aux.raster, base.raster)

    # 2. Change resolution to the resolution of the base layer using nearest neighbour interpolation
    r <- resample(r, base.raster, method = "ngb") 
    
    # 3. Replace NA with a specified value (if appropriate)
    r[is.na(r[])] <- value  

    # 4. Select only the shape of Bangladesh as defined by the base layer
    r <- mask(x = r, mask = base.raster)
    
    # Assign a name to the raster
    names(r) <- label
    return(r)
    
}
```

Function 2 is really similar, but applies the "sum" algorithm instead of nearest neighbour interpolation when changing the spatial resolution, which is a more appropriate method when working with demographic maps from Meta that are of a higher resolution than our base layer. The demographic data from Meta are of a \~30m spatial resolution and require aggregation of the values in each cell when resampled to 100m. Using the nearest neighbour interpolation, we 'lose' people (because data is thrown away in the downsample). The'sum' algorithm instead provides a more accurate representation of population per each 100m grid cell.

Function 2 should therefore be applied to all demographic maps from Meta and will execute the following steps:

1.  Obtain the ratio of spatial resolutions of your layer of interest (from Meta) and the base layer.
2.  Crops your raster to the base layer so that they have the same extent
3.  If appropriate, recode missing values to a specified value.
4.  Change the spatial resolution to match your base layer, on the basis of the ratio defined in Step 1. Note: we are going from a higher to a lower spatial resolution, hence the use of "aggregate".
5.  Mask the raster so that it has the same shape as your base layer.

```{r}
# Function for automating the processing of geo-spatial covariates for use in poverty modelling
geo_process2 <- function(aux.raster, base.raster, label, value) {
  
    # 1. Get spatial resolutions of both rasters 
    res1 <- res(base.raster)
    res2 <- res(aux.raster)
    
    # Save as a factor of ratios 
    factor.ratio <- res1/res2
    factor.ratio <- factor.ratio[[1]]

    # 2. Crop to the base layer so they have the same extent
    r <- crop(aux.raster, base.raster)
    
    # 3. Replace NA with a specified value (if appropriate)
    r[is.na(r[])] <- value  

    # 4. Change resolution to the resolution of the base layer using the "sum"        algorithm
    r <- aggregate(r, fact=factor.ratio, fun=sum, na.rm=TRUE)

    # 5. Select only the shape of Bangladesh as defined by the base layer
    r <- mask(x = r, mask = base.raster)
    
    # Assign a name to the raster
    names(r) <- label
    return(r)
    
}
```

### Step 3 - process accessibility data from the Malaria Atlas

```{r}
# See that all the files have loaded
matlas.rasters

# Now apply this function to a list of rasters from the Malaria Atlas 

# Make a list for storing the processed rasters 
matlas.processed <- list()

# Store the length of the list of rasters
num_r <- 1:length(matlas.rasters)  

# Apply the geo-processing function to all rasters. Here there is no need to replace missing values as 0s (they are already coded as missing), so the parameter for value can stay at NA.
for (i in num_r) { 
matlas.processed[[i]] <- geo_process(aux.raster = matlas.rasters[[i]], base.raster = base.layer.raster, label = matlas.rasters[[i]]@data@names, value = NA)

}

# See the result
matlas.processed

# Plot results 
plot(matlas.processed[[1]], box=F, axes=F, col=viridis(50), main = "Bangladesh - Travel Time to Cities")
plot(matlas.processed[[2]], box=F, axes=F, col=viridis(50), main = "Bangladesh - Motorised Travel Time to Healthcare Facilities")
plot(matlas.processed[[3]], box=F, axes=F, col=viridis(50), main = "Bangladesh - Walking-Only Travel Time to Healthcare Facilities")

# Create a high quality image 
png(filename="maps/BGD travel time city.png", res=400, width=2000, height=1500)
plot(matlas.processed[[1]], box=F, axes=F, col=viridis(50), main = "Bangladesh - Travel Time to Cities")
dev.off()
```

### Step 4 - process the demographic data from Meta

```{r}
# Check that all the files were picked up by this 
fb.rasters

# Make a list for storing the processed rasters 
fblist.processed <- list()

# Store the length of the list of rasters
num_fb <- 1:length(fb.rasters)  

# Apply the geo-processing function to all rasters. Here we need to recode missing values as 0s
for (i in num_fb) { 
fblist.processed[[i]] <- geo_process2(aux.raster = fb.rasters[[i]], base.raster = base.layer.raster, label = fb.rasters[[i]]@data@names, value = 0)

}

# See the result
fblist.processed

# Plot results
plot(fblist.processed[[1]], box=F, axes=F, main = "Bangladesh - Population density (children under 5)")
plot(fblist.processed[[2]], box=F, axes=F, main = "Bangladesh - Population density (elderly 60+)")
plot(fblist.processed[[3]], box=F, axes=F, main = "Bangladesh - Population density (general)")
plot(fblist.processed[[4]], box=F, axes=F, main = "Bangladesh - Population density (men)")
plot(fblist.processed[[5]], box=F, axes=F, main = "Bangladesh - Population density (women)")
plot(fblist.processed[[6]], box=F, axes=F, main = "Bangladesh - Population density (women of reproductive age 15-49)")
plot(fblist.processed[[7]], box=F, axes=F, main = "Bangladesh - Population density (youth 15-24)")

# Create a high quality image 
png(filename="maps/BGD_pop_density_youth.png", res=400, width=2000, height=1500)
plot(fblist.processed[[7]], box=F, axes=F, main = "Bangladesh - Population density (youth 15-24)")
dev.off()
```

### Step 5 - Process nightlights data

```{r}
# Apply the geo processing function
nightlights.raster.processed <- geo_process(aux.raster = nightlights.raster, base.raster = base.layer.raster, label = "Nightlights_data", value = 0)

# Check raster
nightlights.raster.processed

# Plot raster 
plot(nightlights.raster.processed, axes=F, box=F, main = "Nightlights data in Bangladesh", col=cividis(50))

# Create a high quality image 
png(filename="maps/nightlights_BGD.png", res=400, width=2000, height=1500)
plot(nightlights.raster.processed, box=F, axes=F, main = "Nightlights data in Bangladesh", col=cividis(50))
dev.off()
```

### Step 6 - Inspect pre-harmonised World Pop datasets

```{r}
# See that all the files have loaded
worldpop.rasters

#Plot examples of WorldPop datasets
plot(worldpop.rasters[[11]], box = F, axes = F, main = "Distance to the closest road Bangladesh", col=viridis(50))
```

### Step 7 - Convert shapefile to a raster

```{r}
# Copy admin unit codes to new column in upazila shapefile attributes, in the process removing Bangladesh prefix from the integer code
shapefile.zonal@data$adm3_integer <- substr(shapefile.zonal@data[["ADM3_PCODE"]], 3, 10)

# Turn into numeric
shapefile.zonal@data[["adm3_integer"]] <- as.numeric(shapefile.zonal@data[["adm3_integer"]])

# Convert upazila shapefile to raster using the integer admin unit code, maintaining extent and cell size of L0 base layer
## Set up a raster "template" to use in rasterize()
ext_base <-  extent(base.layer.raster)
ncol_base <- base.layer.raster@ncols
nrow_base <- base.layer.raster@nrows

xy <- abs(apply(as.matrix(bbox(ext_base)), 1, diff))
r <- raster(ext_base, ncol=ncol_base, nrow=nrow_base)

## Rasterize the shapefile
raster_admin3 <-rasterize(shapefile.zonal, r, field=shapefile.zonal$adm3_integer)

# Assign the same CRS as the base layer 
crs_base <- crs(base.layer.raster)
crs(raster_admin3) <- crs_base

# Plot to see if values have been assigned to the raster
plot(raster_admin3, box=F, axes=F, legend=F)


```

### Step 8 - Calculation of zonal statistics

```{r}
# Make a list with all the rasters 
full.raster.list <- c(matlas.processed, fblist.processed, worldpop.rasters, nightlights.raster.processed)

# Check rasters 
full.raster.list

# Create a raster stack
raster.stack <- stack(full.raster.list)

# Zonal statistics 

# Mean
zonal.stats.mean <- zonal(raster.stack, raster_admin3, fun='mean', digits=6, na.rm=TRUE)
zonal.stats.mean <- as.data.frame(zonal.stats.mean)
colnames_mean <- colnames(zonal.stats.mean)  # gather column names
colnames_mean <- paste(colnames_mean, "mean", sep="_")  # add identifier for mean
colnames_mean <- colnames_mean[2:28]  # exclude zone
colnames(zonal.stats.mean)[2:28] <- colnames_mean  # rename columns
 

# Min
zonal.stats.min <- zonal(raster.stack, raster_admin3, fun='min', digits=6, na.rm=TRUE)
zonal.stats.min <- as.data.frame(zonal.stats.min)
colnames_min <- colnames(zonal.stats.min)
colnames_min <- paste(colnames_min, "min", sep="_")
colnames(zonal.stats.min)[2:28] <- colnames_min[2:28]

# Max
zonal.stats.max <- zonal(raster.stack, raster_admin3, fun='max', digits=6, na.rm=TRUE)
zonal.stats.max <- as.data.frame(zonal.stats.max)
colnames_max <- colnames(zonal.stats.max)
colnames_max <- paste(colnames_max, "max", sep="_")
colnames(zonal.stats.max)[2:28] <- colnames_max[2:28]

# Sum
zonal.stats.sum <- zonal(raster.stack, raster_admin3, fun='sum', digits=6, na.rm=TRUE)
zonal.stats.sum <- as.data.frame(zonal.stats.sum)
colnames_sum <- colnames(zonal.stats.sum)
colnames_sum <- paste(colnames_sum, "sum", sep="_")
colnames(zonal.stats.sum)[2:28] <- colnames_sum[2:28]

# SD
zonal.stats.sd <- zonal(raster.stack, raster_admin3, fun='sd', digits=6, na.rm=TRUE)
zonal.stats.sd <- as.data.frame(zonal.stats.sd)
colnames_sd <- colnames(zonal.stats.sd)
colnames_sd <- paste(colnames_sd, "sd", sep="_")
colnames(zonal.stats.sd)[2:28] <- colnames_sd[2:28]

# Count
zonal.stats.count <- zonal(raster.stack, raster_admin3, fun='count', digits=6, na.rm=TRUE)
zonal.stats.count <- as.data.frame(zonal.stats.count)
colnames_count <- colnames(zonal.stats.count)
colnames_count <- paste(colnames_count, "count", sep="_")
colnames(zonal.stats.count)[2:28] <- colnames_count[2:28]

# Make a list of all dataframes that contain zonal statistics
l.df <- lapply(ls(pattern="zonal.stats"), function(x) get(x))

# Combine all zonal statistics into one data frame 
zonal.stats.all <- bind_cols(l.df)

# Delete repeated columns for zones - occurs every 28 variables 
zonal.stats.all = subset(zonal.stats.all, select = -c(29, 57, 85, 113, 141)) 

# Rename the colum with upazila codes
colnames(zonal.stats.all)[1] <- "upazila.code"

# Save file 
save(zonal.stats.all, file = "C:/Users/idabr/OneDrive - Oxford Policy Management Limited/EMDI SAE/Geo-spatial Bangladesh data/BGD.zonalstats.RData")
```

Save my Rdata

```{r}
# Save the RData file 
save.image("C:/Users/idabr/OneDrive - Oxford Policy Management Limited/EMDI SAE/Geo-spatial Bangladesh data/Quarto github workspace.RData")

```

## 4. Caveats, problems, things to look out for
