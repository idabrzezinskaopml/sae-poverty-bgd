---
title: "Guide to processing of geo-spatial covariates to be used in poverty modelling - an example of Bangladesh"
author: "Ida Brzezinska"
format: html
editor: visual
---

# Introduction

Nick - you can paste your introduction here.

# Section A: Geo-spatial

::: callout-note
## Glossary

**Raster data** refers to any gridded (or pixelated) data where each pixel represents a specific geographical location. The value can be continuous (e.g. temperature) or categorical (e.g. land use).

V**ector data** represents structures on the Earth's surface that are defined by discrete locations (x,y) called vertices. Depending on how the vertices (x,y) are oragnised, we can divide vector data types into: **points, lines, and polygons**.

**Extent**: the maximum and minimum values of longitude and latitude that define the boundaries of our spatial structure.

**Map projections** try to portray the surface of the earth or a portion of the earth on a flat piece of paper or computer screen. 

**Coordinate Reference System (CRS)** - defines, with the help of coordinates, how the two-dimensional projected map in our GIS is related to real places on Earth.

**Geographic Information System (GIS)** - a system that creates, manages, analyses, and maps data. GIS connects data to a map, integrating location data (where things are), with all types of descriptive information (what things are like there).

**Spatial resolution** of a raster describes the area that each pixel covers. For example, a 1km x 1km spatial resolution will be a grid where each grid cell covers and area of 1km x 1km. The smaller the area covered, the higher the spatial resolution (i.e. the more we "zoom in").

**Nearest neighbour interpolation -** a method for resampling, i.e. changing the spatial resolution of rasters used in remote sensing, where each "corrected" pixel is assigned a data value of the "uncorrected" pixel that is closest to it in terms of coordinate location.

**Resampling using the "sum" algorithm** - a method for resampling, i.e. changing the spatial resolution of a raster used in remote sensing. This is considered the appropriate method when aggregating high-resolution *demographic* data to a coarser grid.
:::

## 1. Introduction

Section A is our first step into poverty modelling in Bangladesh. Here, we will obtain and transform various geo-spatial datasets (such as accessiblity, nightlights intensity, demographic maps, and topography) into predictors of poverty rates. Geo-spatial datasets can be important inputs in poverty estimation, particularly in context where other data such as census is unavailable and household survey samples are too small to produce reliable statistics at a disaggregated zonal level. Geo-spatial data has many advantages: it is open source, has wide coverage, high spatial resolution, and is frequently updated (in theory you could have a dynamic poverty map which updates itself as new geo-spatial data becomes available!).

The main goal of Section A will be to produce a "**harmonised geo-spatial covariate raster for poverty modelling**". In other words, layers of geo-spatial information in a raster format (a collection of pixels) for each upazila that we can use to predict poverty. Imagine that each upazila is divided into pixels. Each pixel will contain some geo-spatial information: slope, travel time to healthcare facilities, distance to nearest water source etc. Harmonising them means that all of our geo-spatial layers are in the same format: CRS, extent, spatial resolution, and shape. Why is this necessary? Short answer: so that each pixel with values of geo-spatial data describes the same location across all our geo-spatial datasets.

Long anwer: In order to predict poverty rates for upazilas, we need to know some basic statistics (mean, max, min, sd etc.) for the values of our geo-spatial variables at upazila level. For example: what is the mean population density of women and nightlights intensity in each upazila in Bangladesh? We would only be able to answer this question if our layers showing population density for women and nightlights were aligned: they had the same CRS (projection), extent (maximum and minimum values of geographical coordinates), spatial resolution (size of pixels), and shape of Bangladesh. That is, we need comparable pixels with data values that can be assigned to upazilas.

Finally, we will need a shapefile that defines the boundaries of each administrative zone and turn it into a raster (again, a collection of pixels) - so that we can assign each pixel with geo-spatial information to the right upazila.

Figure XX below demonstrates the process in seven steps:

**Step 1**: Load all datasets. I have divided those into 6 categories:

1.  Base raster layer - this raster contains the target values of parameters, such as: CRS, extent, spatial resolution, and shape. We will be harmonising to this base layer, i.e. we want all our other layers to look like this one.
2.  Shapefile with zonal boundaries - we need this to define the administrative boundaries of upazilas in Bangladesh.
3.  Nightlights intensity data
4.  Malaria Atlas data on accessibility
5.  Meta Demographic Maps
6.  WorldPop Harmonised data on Topography.

Datasets no. 3-5 will need harmonising, while the World Pop datasets are pre-harmonised and do not need any processing from us.

**Step 2**: Set extent the same as the Base Layer. We want our layers to cover just Bangladesh (as opposed to, for example, the entirety of South-East Asia). Setting the extent will ensure that we are working within the same range of coordinates.

**Step 3**: Change the spatial resolution to that of the Base Layer (\~100m). This means all our data will be organised into pixels covering an area of 100m x 100m.

**Step 4**: (only for Meta Demographic Maps): recode missing values as 0s.

**Step 5**: Mask to obtain the "shape" of Bangladesh.

**Step 6**: Convert the shapefile with administrative boundaries of upazilas in Bangladesh to a raster (a collection of pixels each indexed to the correct upazila).

**Step 7**: Estimate zonal statistics (mean, max, min, sd etc.) for each geo-spatial dataset for each upazila.

![](images/diagram%20vol%202.png)

## 2. Theory - key concepts in Geo-spatial analysis

Let us start with the two most burning questions: What is geo-spatial data and what is a GIS?

**Geo-spatial data** in the simplest terms is any type of data referenced to a specific location on Earth. It consists broadly of two elements: **1) location data** (where things are) and **2) attributes data** (what things are like there). Location data allows us to position our data values adequately on the surface of the Earth. Attributes data describes any features of that specific location (temperature, elevation, road type, a bridge, demographic information and so on).

**Geographic Information System (GIS)** is a system that creates, manages, analyses, and maps data. GIS connects data to a map, integrating location data , with all types of descriptive information.

### 2.1. Geo-spatial data sources

#### Traditional surveys

Recall that geo-spatial data is simply a set of data values that are indexed to a geographical location on Earth. In that sense, traditional census or surveys are sources of geo-spatial data as long as they contain information on administrative units, GPS location, or any other geographical identifiers. Data coming from traditional surveys can even be more precise, for instance if we are interesetd in measuring a building and its properties.

#### Remote sensing

Increasingly, **remote sensing** data collection is turning out to be a more efficient method than surveys. This includes satellite imagery and aircraft sensors that orbit the Earth and collect data continuously, at a high spatial resolution, and globally, including places that would be hard to reach with a survey (say the middle of the ocean or conflict-affected areas). In fact, due to the advantages of remote sensing data collection - space is becoming a crowded place, and increasingly more so in the last couple of years. Figure X below shows the time trend of the annual number of objects launched into space, which explodes upwards after around 2015. As of 2022, there were 6,905 active satellites in space. In this workflow, we will be working exclusively with remote sensing data, but let us briefly consider other sources of geo-spatial information.

![](images/Objects%20launched%20into%20space.png){width="573"}

Source: [Our World in Data](https://ourworldindata.org/space-exploration-satellites)

#### Crowdsourcing

For all the growing interest in remote sensing data collection, it is worth acknowledging that highly valuable geo-spatial information often comes from humans on the ground! Crowdsourcing geo-spatial data is often done via informal social networks and does not require any formal training in geo-spatial technologies. Perhaps one of the most notable examples is [Open Street Map](https://www.openstreetmap.org/about) (OSM), a community of mappers with local knowledge that produce open source maps. The [Humanitarian team at OSM](https://www.hotosm.org/) produces community-developed maps in areas such as Disasters & Climate Resilience or Public Health - [for example](https://www.hotosm.org/projects/integrating-openstreetmap-data-into-caribbean-disaster-response-efforts-geocris/), OSM is working with the World Bank and the Caribbean Disaster Emergency Management Agency (CDEMA) to integrate their maps into official disaster risk response.

#### Cell phone data

Basic services provided by cell phone operators are routed by satellites, providing location information at various levels of precision (from GPS to cell phone tower), together with Call Detail Records (CDR). [Flowminder](https://www.flowminder.org/about-us) is an example of an organisation that leverages mobile operator data in development projects, for instance tracking population movements post the 2015 Nepal Earthquake.

#### Online data

Online data is broad and includes all data shared online purposefully, including Wikipedia, social media, online articles etc. Location and mobility tracking via social media can be another source of geographical information. App-based mobile phone location data is actually often of higher spatial resolution than that coming from cell phone data operators and is increasingly being used in mobility studies. In fact, we will be using high-resolution population density estimates from Meta (previously Facebook) in our poverty modelling exercise.

### 2.2. Data structures

I want to introduce the two most common spatial data types, which we will be working with in our poverty mapping exercise, together with their attributes.

::: callout-important
## Important

An important note on the naming conventions and structures of geographical coordinates in geo-spatial data. A set of coordinates will typically be expressed as **(x,y), where x relates to longitude and y to latitude**. Latitude has a range (-90, 90), while longitude has a range (-180, 180). Negative values of longitude refer to the Western hemisphere and positive values to the Eastern hemisphere. Similarly, negative values of latitude refer to the Southern hemisphere and positive values refer to the Northern hemisphere.
:::

#### 2.2.1. Raster data

**Raster data** refers to any gridded (or pixelated) data where each pixel represents a specific geographical location. The value can be continuous (e.g. temperature) or categorical (e.g. land use). If pixels sound familiar, it's because they are - in fact, this is how every digital image is represented. The only difference is that a raster additionally includes spatial information that connects data from the image to a particular location. The location is defined by the following attributes (these are important attributes to inspect when you first open your raster):

-   Extent

-   Cell size (spatial resoluton or size of each pixel)

-   The number of rows and columns

-   Coordinate Reference System (CRS)

    To illustrate this concept, below is a raster image showing the elevation of Harvard Forest. Each pixel has values of elevation assigned, which range from 0-9. Here, the spatial resolution is 1m x 1m, which means each pixel has an area of 1m by 1m (this is really granular!).

    ![](images/Raster%20image.png){width="574"}

Source: [National Ecological Observatory Network](https://www.neonscience.org/)

Mention file extensions of raster data?

#### 2.2.2. Vector data

**Vector data** represents structures on the Earth's surface that are defined by discrete locations (x,y) called vertices. Depending on how the vertices (x,y) are oragnised, we can divide vector data types into: **points, lines, and polygons**. You could think of: locations of hospitals, road networks, administrative boundaries.

![](images/Geometry%20vector.png){width="568"}

Source: [National Ecological Observatory Network](https://www.neonscience.org/)

To illustrate this concept, below is a vector data set with lines showing the road network in Ghana, developed through Open Street Maps Ghana, downloadable via the Humanitarian Data Exchange website. Each line is determined by its vertices (think of them as the (x,y) points shown in the image above) and indexed geographically in space.

![](images/Ghana%20road%20network.png){width="648"}

Source: [Humanitarian Data Exchange](https://data.humdata.org/dataset/hotosm_gha_roads)

Vector data comes in many formats, but we will be working with the (very common) Shapefile format, which has a .shp extension. More specifically, we will download a shapefile containing multipolygons that define adminsitrative boundaries of upazilas (admin level 3) in Bangladesh. A shapefile stores the coordinates of vertices, as well as other metadata:

-   Extent

-   Object type - whether the shapefile contains points, lines, or polygons.

-   Coordinate Referenec System (CRS)

-   Other attributes - e.g. in our case the name of the upazila, its administrative code, area covered etc.

Could have a short quiz here showing different images and asking the audience whether this is a raster or a vector dataset.

### 2.3. Layering geo-spatial data sets

Now that you are familiar with the basic types of geo-spatial datasets, we can start thinking about performing some simple mapping. Typically, rather than viewing each layer of data (such as your road network, elevation, temperature etc.) individually, it is valuable to overlay them on top of each other, so that we can view multiple geo-spatial layers at the same time. The diagram in Figure XX below demonstrates this concept: while we can inspect data on streets, buildings, and vegetation individually, a much more interesting way to look at these layers is by viewing the simultaneously, as in the "Integrated data" portion of the diagram at the very bottom.

![](images/Data%20layers.jpg){width="555"}

Source: [National Geographic](https://education.nationalgeographic.org/resource/geographic-information-system-gis/)

::: callout-caution
## Caution

Make sure that the CRS is the same for all of your objects before layering. The most standard CRS is the World Geodetic System 1984 (WGS 84), but you may encounter other ones when working with spatial data for specific regions of the world.
:::

Now, let's see an example of visualising multiple raster layers from our project work under [Data & Evidence to End Extreme Poverty (DEEP)](https://povertyevidence.org/). In this case, we wanted to map the spatial distribution of climatic risks in Nigeria, looking at droughts and floods. Figure XX below shows the worst drought (defined as Standardized Precipitation Evapotranspiration Index or SPEI below -1.5) and all flooded areas in the period 2010-2020 in Nigeria, on top of an Open Street Map background. Drought is captured by a continuous variable for a range of values of SPEI, while flood is a categorical variable (i.e. flood or no flood), with flooded areas shown in blue. We can see that the extent of these layers differs, i.e. drought is only defined within Nigeria (including bordering grid cells), while flood data extends beyond the borders of Nigeria and considers an entire river system, which is not necessarily bound by national borders.

![Rasters showing all floods and the worst droughts in Nigeria between 2010-2020](images/Nigeria%20flood%20drought%20.png)

The two layers (drought and flood) also have different spatial resolutions. Here, drought data is of a lower spatial resolution, i.e. it comes up as big pixels of around 0.5 degrees (or \~30km), while flood data is extremely high resolution, with each pixel the size of \~250m x 250m, coming from the NASA MODIS satellite. Figure XX below shows a zoom into two grid cells of drought data, which contain numerous grid cells with flood data. The higher the spatial resolution, the smaller your grid cells!

![Zoom into pixels showing floods and droughts in Nigeria](images/Pixel%20zoom%20in%20.png)

### 2.4. Raster manipulation for poverty modelling

The previous section introduced the concept of working with multiple layers of geo-spatial information. In our example, the two layers, despite being displayed on top of each other, had very different attributes: spatial resolution, cell sizes, extent . However, there are cases, as in the poverty modelling exercise we are about to do, where we want to "harmonise" our raster objects, i.e. make sure all the attributes (CRS, extent, spatial resolution, cell size) are the same when rasters are overlaid on top of each other.

Let's consider our problem at hand again: **We want to compute zonal poverty statistics at administrative level 3 (upazila) level in Bangladesh.** We will do so by using statistical modelling and a number of remote sensed covariates as our predictors. For this, we need some basic statistics (mean, min, max, standard deviation, count etc.) that describe our geo-spatial information for each upazila. For example, what is the mean Travel Time to Healthcare Facilities (in minutes) in the upazila of Abador? Or, what is the median nightlights intensity in that upazila? While R is smart enough to compute those statistics for us automatically, we need to provide it with a nicely harmonised set of rasters. We will use a "base layer", which contains all the attributes we are interested in, and harmonise all other remote sensing covariates to our base layer. That is: we will match the CRS, extent, spatial resolution, cell size of the base layer.

With that in mind, I will introduce a few ways in which we will manipulate spatial data. This is a useful skill to have as we will soon discover that raw open source data can be a little messy and you may need to implement some of these steps to make sense of your data before any meaningful analysis.

1.  **Cropping -** changing the extent of our spatial objects, i.e. the maximum and minimum values of longitude and latitude that define the object, to that of the base layer.
2.  **Resampling** - changing the spatial resolution so that it matches that of the base layer.
3.  **Recoding missing values** - (only if appropriate) changing missing values to a specified value.

::: callout-caution
## Caution

A note of caution on missing values in geo-spatial data. As with every data type, the treatment of missing values can be a source of philosophical discussions and should always be determined depending on the context and the specific problem at hand. The user should always ask themselves: can a missing value be interpreted as a zero or do we simply not have enough information to conclude? If it is a zero, missing values should be recoded accordingly.
:::

4.  **Masking** - cutting the exact "shape" of a raster layer. This is different from cropping, which would leave us with a chunky box that contains Bangladesh, but also some areas between the maximum and minimum values that fall outside of Bangladesh. We can use the mask function to examine only the country boundaries.

These concepts may seem a little abstract for now, so let us consider visually what each of these processes will entail. Let's take the example of processing geo-spatial data on nightlights intensity for Bangladesh - a process we will be implementing in Step 5 of Section 3. Night lights intensity has been widely used in literature as a proxy for income and will be one of our predictors of poverty. Figure XX shows a TIFF file with the aerial shot of nightlights intensity in South-East Asia as seen from space. We can see that urban areas and areas with higher density of economic activity appear more luminous. We will use the functions described above to manipulate this TIFF file and transform it into a raster layer for Bangladesh with codified values of radiance per pixel (this is a measure of nightlights intensity).

![](images/Nightlights%20data%20-01.png)

Figure XX below shows the processing of data on nightlights intensity. The left hand side is what you will see if you simply load the above TIFF file into your R environment, turn it into a raster, and plot - in other words, not much. Although it is a little difficult to see, the original raster is showing values of nightlights intensity for the entire South East Asia region at the orginal spatial resolution of around \~450m. First, we are interested in analysing just Bangladesh, rather than the entirely of South East Asia (not least because TIFF files can be quite heavy and maintaining unnecessarily large raster objects slows down a lot of the computation). We will "crop" our raster object to the Bangladesh base layer, i.e. we will change the extent to that of Bangladesh. Now, our raster object changed dimensions. It is defined by the maximum and minimum values of longitude and latitude in Bangladesh.

The next step in the process is to resample the raster, i.e. change the spatial resolution to \~100m to match that of our base layer. Going from a lower to a higher spatial resolution is called disaggregation. If we zoomed into the image under "resample", we would see more smaller pixels appear than previously. Finally, we want to view the "shape" fo Bangladesh, rather than a rectangular box bound by its extent. For this purpose, we "mask" our raster layer with nightlights to the base layer - and we finally achieve a nicely formatted raster that resembles Bangladesh!

![](images/Nightlights%20data%20processing.png)

Note that the nightlights raster did not contain missing values and any location with no radiance was coded as having a value of zero nightlights intensity. There are cases, however, where we should be more careful about the interpretation of missing values vs. zeros. In our next example, we will go through the processing of high-resolution demographic maps from Meta, specifically the population density of youth aged 15-24 - a process we will be implementing in Step 4 of Section 3. The left hand side of Figure XX below shows the result from simply plotting the raster from the original TIFF file. We can see a few colour-coded values of population density, but most of the raster is empty (NAs shown in white). Here, the user should consider: are the values missing because there are no people in this location? Or is it because we haven't collected data on those locations? In our case, the documentation tells us that missing values are equivalent to there being no people aged 15-24. After recoding NA values as 0s, we see that the raster layer is now populated with values (zeros shown in grey).

As in the example of nightlights, we want to crop our raster so that it has the extent of Bangladesh. Afterwards, we will change the spatial resolution to \~100m. Note that the population density data is originally of a higher spatial resolution (of around \~30m), so in this case we are resampling to a coarser grid. This process is called aggregation. Since we are deploying the "sum" algorithm, we can observe that the legend beside the plot has changed - we now have larger density of people per pixel (since our pixels just got bigger as a result of aggregation). The final step is to mask our raster with demographic data to the base layer - and we end up with a nice shape of Bangladesh.

![](images/FB%20data%20processing.png)

These are exactly the processing steps that we will be carrying out in our next session, although they will all be automated with a single function for ease of application.

### 2.5. Spatial Data in R

Given that our entire workflow will be carried out in R to make it accessible, open source, and user-friendly - we will introduce some common spatial objects in R. There are numerous packages that allow you to work with spatial data. In fact, packages are very often retired and new ones are created to replace them. We will be relying mostly on:

1.  The `sp` and `sf` packages for vector data
2.  The `raster` package for raster data
3.  The `rgdal` package for manipulation of geo-spatial data using the GDAL library.

#### 2.5.1. Vector data with `sp` package

Recently spatial data in R has been standardised using the base package `sp`. Although a newer version of this package exists, called `sf` , it is useful to understand basic data structures under `sp`. Let's have a look at the spatial data classes by running the chunk below:

```{r}
library(sp)
getClass("Spatial")
```

A basic `sp` object will have two "slots": a bounding box `bbox` containing a matrix of longitude and latitude values (or, using the language we introduced earlier, the extent of an object) and `proj4string`, which is the CRS. These parameters will help us locate our object in space. **The basis of all the spatial objects is a matrix or data frame with latitude and longitude values - this is what we need to make our existing objects in R "spatial".** From the output above, we can also see that objects build on each other. This is illustrated in Figure XX below. For example, taking our matrix or data frame with latitude and longitude, we can create a `SpatialPoints` object, which would simply be a collection of spatial points. We can build on this and create a `SpatialPointsDataFram`e by adding a data frame with attributes associated with these points. The same can be done for lines and polygons.

![](images/spatial%20objects%20in%20R.png)

#### 2.5.2 Vector data with `sf` package

The `sf` package implements [Simple Features](https://en.wikipedia.org/wiki/Simple_Features), which is a set of standards that specify storage and model of geographic features used in geographic information systems. It is famous enough to have its [Wikipedia page](https://en.wikipedia.org/wiki/Simple_Features) and is endorsed by the Open Geospatial Consortium. It works only with vector data and does not accommodate rasters. Common geometry types are shown in Figure XX below. Among the primitive ones, we have `Points`, `LineStrings`, and `Polygons` (the same as simple vector geometry types discussed in Section 2.2.) The `sf` package allows for multipart geometries, essentially a collection of primitive geometries, such as: `MultiPoints`, `MultiLineString`, and `MultiPolygons`. The coordinates in brackets specify each vertex that defines the geometry.

![](images/sf%20package%20primitive%20geometries.png)

![](images/multipart%20geometries.png)

Source: [Wikipedia](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry)

`sf` objects are organised into three features (see Figure XX below):

1.  `sf`, the data frame with feature attributes (for example, administrative codes) and feature geometries (green box).
2.  `sfc,` the simple feature geometry list-column (red box).
3.  `sfg`, the simple feature geometry (blue box). In this case, a multipolygon.

![](images/multipolygon%20feature%20.png)

Source: [CRAN project, sf vignette](https://cran.r-project.org/web/packages/sf/vignettes/sf1.html)

#### 2.5.3. Raster data with `raster` package

This is the main geo-spatial data type we will be working with for our poverty modelling exercise. The `raster` package provides functions that allow us to read and write any raster object and perform raster operations such as those described in Section 2.4. (resampling, masking, cropping, recoding NAs etc.). It supports three classes of objects: `RasterLayer` (a single raster), `RasterStack`(multiple rasters stacked on top of each other that can still be viewed as individual files), `RasterBrick` (similar to `RasterStack` but in a single file).

To explore the structure of raster data let us create en empty (no data values) raster from scratch by running the code below. We will specify the following parameters:

-   Number of rows and columns.

-   Extent (minimum and maximum values of longitude and latitude).

```{r}
library(raster)
r <- raster(ncol=10, nrow = 10, xmx=-116,xmn=-126,ymn=42,ymx=46)
r
```

Note that just specifying the number of rows and column and extent was sufficient to create a `RasterLayer` object. The number of rows and columns defined our spatial resolution of the raster. In addition, the standard CRS `+proj=longlat +datum=WGS84 +no_defs` was automatically assigned. At the moment, our raster is empty, i.e. it is simply a grid with no data values. Let us generate some data to populate the raster by assigning random values from the unit distribution to each grid cell.

```{r}
r[] <- runif(n=ncell(r))
r
```

Now the summary of our RasterLayer object includes minimum and maximum values of our randomly generated data. Let's visualise this!

```{r}
plot(r)
```

### 2.6 Homework

1.  [Visualising Spatial Data in R at DataCamp](https://app.datacamp.com/learn/courses/visualizing-geospatial-data-in-r) OR [Spatial Objects in R](https://cengel.github.io/rspatial/2_spDataTypes.nb.html) (optional for those that wish to become familiar with spatial objects in R and creating those from scratch).
2.  **Download the "Geo-spatial Bangladesh data" zip file, unzip it, and save it in your working directory. Your folder structure after unzipping should look like this:**

![](images/folder%20structure%20vol%202-01.png)

I would recommend not rearranging the files across folders. Keeping this structure will make it easy to run your code in Section 3 as you will only need to replace the base Working Directory with your own and everything else should run from there!

::: callout-warning
## Warning

Just a heads up that the files we will be working with are very large. The .zip file itself is is 5GB, while all the files after unzipping will take up around 34GB of space. Please make sure you have sufficient memory on your machine. If you are using an online storage solution, you might want to temporarily offload other files you are not currently using to the cloud.
:::

## 3. Applying this

In Section 2 we covered key theoretical concepts in geo-spatial analysis, including the sources of such data, most common structures, data manipulation and types of spatial objects you might encounter in R. In this section we are going to apply this to a practical problem: **we will prepare the geo-spatial covariates (on accessibility, nightlights, topograhy, and demography) that will be used for poverty estimation in Section B**. Recall that there are two main types of geo-spatial data: vector and raster. We will primarily be working with raster data and performing what we will call a "harmonisation" - that is, bringing all the rasters to the same extent, shape, spatial resolution, and projection as the base raster layer. Let's begin with exploring the data sources we will use in this exercise.

### Data sources - Bangladesh

We will be working with the following data sets:

1.  **Base layer**: WorldPop Administrative Level 0 mastergrid base layer for Bangladesh at \~100m spatial resolution. This mastergrid defines the administrative boundaries of the country, to which we will be harmonising all other geo-spatial datasets, i.e. matching the spatial resolution, CRS, extent, and shape.

2.  **Shape file**: Subnational Administrative Boundaries for Bangladesh from the Humanitarian Data Exchange. This file contains the administrative boundaries of the zones for which we will be estimating poverty. In our case, this is done at administrative level 3 (upazila) in Bangladesh.

3.  **Malaria Atlas data on accessibilit**y, including: travel time to cities and healthcare facilities.

4.  **Demographic maps from Meta** at \~30m spatial resolution raster showing population density of different demographic groups (men, women, youth, elderly etc.).

5.  **Nightlights data** at \~450m spatial resolution with almost global coverage.

6.  **World Pop** Pre-harmonised geo-spatial datasets: available for all countries. The datasets includes information on topography, slope, Open Street Map distance to closest road, waterway, and various land cover classes. Note that this data has already been harmonised to our base layer and hence will not require any processing in this script.

### Base layers

| Geo-spatial file name             | Description                                                          | Year | Link to download                                                                                                               |
|:------------|:---------------|:------------|:-------------------------------|
| bgd_level0_100m_2000_2020.tif     | WorldPop Administrative Level 0 mastergrid base layer for Bangladesh | 2020 | [World Pop Hub - National boundaries](https://www.worldpop.org/geodata/summary?id=24282)                                       |
| bgd_admbnda_adm3_bbs_20201113.shp | Administrative Level 3 (Upazila) Units in Bangladesh                 | 2015 | [Bangladesh - Subnational Administrative Boundaries - Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-bgd) |

### Geo-spatial data sets to be harmonised

|                                                                             |                                                                              |      |                                                                                                                                                                                                                                                                                                  |
|------------|------------|:-----------|--------------------------------------|
| **Geo-spatial file name**                                                   | Description                                                                  | Year | Link to download                                                                                                                                                                                                                                                                                 |
| SVDNB_npp_20150101-20151231_75N060E_vcm-orm_v10_c201701311200.avg_rade9.tif | VIIRS night-time lights (global)                                             | 2015 | [Earth Observation Group](https://eogdata.mines.edu/products/vnl/#v1)                                                                                                                                                                                                                            |
| 2015_accessibility_to_cities_v1.0.tif                                       | MAP travel time to high-density urban centres (global)                       | 2015 | [Malaria Atlas - Accessibility to Cities](https://data.malariaatlas.org/maps?layers=Accessibility:201501_Global_Travel_Time_to_Cities,Malaria:202206_Global_Pf_Parasite_Rate)                                                                                                                    |
| 2020_motorized_travel_time_to_healthcare.tif                                | MAP motorised only travel time to healthcare facilities (global)             | 2019 | [Malaria Atlas - Motorised Time Travel to Healthcare](https://data.malariaatlas.org/maps?layers=Accessibility:202001_Global_Motorized_Travel_Time_to_Healthcare,Malaria:202206_Global_Pf_Parasite_Rate&extent=-11815912.856289707,-6356003.33856192,28286163.259866484,14615055.359158086)       |
| 2020_walking_only_travel_time_to_healthcare.tif                             | MAP walking only travel time to healthcare facilities (global)               | 2019 | [Malaria Atlas - Walking Only Time Travel to Healthcare](https://data.malariaatlas.org/maps?layers=Accessibility:202001_Global_Walking_Only_Travel_Time_To_Healthcare,Malaria:202206_Global_Pf_Parasite_Rate&extent=-11815912.856289707,-6356003.33856192,28286163.259866484,14615055.359158086) |
| bgd_general_2020.tif                                                        | Meta (Facebook) Population density -- Overall; BGD                           | 2020 | [Humanitarian Data Exchange - Demographic Maps from Meta](https://data.humdata.org/dataset/bangladesh-high-resolution-population-density-maps-demographic-estimates)                                                                                                                             |
| bgd_men_2020.tif                                                            | Meta (Facebook) Population density -- Men; BGD                               | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_elderly_60_plus_2020.tif                                                | Meta (Facebook) Population density -- Elderly (aged 60+); BGD                | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_women_of_reproductive_age_15_49_2020.tif                                | Meta (Facebook) Population density -- Women of reproductive age (15-49); BGD | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_women_2020.tif                                                          | Meta (Facebook) Population density -- Women; BGD                             | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_youth_15_24_2020.tif                                                    | Meta (Facebook) Population density -- Youths aged 15-24; BGD for 2020        | 2020 |                                                                                                                                                                                                                                                                                                  |
| bgd_children_under_five_2020.tif                                            | Meta (Facebook) Population density -- Children under 5; BGD                  | 2020 |                                                                                                                                                                                                                                                                                                  |

### WorldPop harmonised geo-spatial data sets

|                                           |                                                                         |           |                                                                |
|---------------|-----------------------|---------------|--------------------|
| **Geo-spatial File Name**                 | **Description**                                                         | **Year**  | **Link to Download**                                           |
| bgd_srtm_topo_100m.tif                    | SRTM topography in BGD                                                  | 2000      | [World Pop](https://www.worldpop.org/project/categories?id=14) |
| bgd_srtm_slope_100m.tif                   | SRTM slope (derivative of topography) in BGD                            | 2000      |                                                                |
| bgd_esaccilc_dst040_100m_2014.tif         | Distance to ESA-CCI-LC woody-tree area edges in BGD                     | 2014      |                                                                |
| bgd_esaccilc_dst140_100m_2014.tif         | Distance to ESA-CCI-LC herbaceous area edges in BGD                     | 2014      |                                                                |
| bgd_osm_dst_road_100m_2016.tif            | Distance to OSM major roads in BGD                                      | 2016      |                                                                |
| bgd_esaccilc_dst150_100m_2014.tif         | Distance to ESA-CCI-LC sparse vegetation area edges in BGD              | 2014      |                                                                |
| bgd_osm_dst_roadintersec_100m_2016.tif    | Distance to OSM major road intersections in BGD                         | 2016      |                                                                |
| bgd_esaccilc_dst160_100m_2014.tif         | Distance to ESA-CCI-LC aquatic vegetation area edges in BGD             | 2014      |                                                                |
| bgd_osm_dst_waterway_100m_2016.tif        | Distance to OSM waterways in BGD                                        | 2016      |                                                                |
| bgd_esaccilc_dst190_100m_2014.tif         | Distance to ESA-CCI-LC artificial surface edges in BGD                  | 2014      |                                                                |
| bgd_esaccilc_dst011_100m_2014.tif         | Distance to ESA-CCI-LC cultivated area edges in BGD                     | 2014      |                                                                |
| bgd_esaccilc_dst200_100m_2014.tif         | Distance to ESA-CCI-LC bare area edges in BGD                           | 2014      |                                                                |
| bgd_esaccilc_dst_water_100m_2000_2012.tif | Distance to ESA-CCI-LC inland water in BGD                              | 2012      |                                                                |
| bgd_wdpa_dst_cat1_100m_2014.tif           | Distance to IUCN strict nature reserve and wilderness area edges in BGD | 2014      |                                                                |
| bgd_esaccilc_dst130_100m_2014.tif         | Distance to ESA-CCI-LC shrub area edges in BGD                          | 2014      |                                                                |
| bgd_dst_coastline_100m_2000_2020.tif      | Distance to open water coastline in BGD                                 | 2000-2020 |                                                                |

### Libraries

Throughout this workflow, we will be using functions from the packages shown in the chunk below. Most of them allow for manipulation of spatial objects in R, others are used to enhance our data visualisations. All the below packages need to be installed and loaded in order for the workflow to run smoothly. If you don't already have some of the below packages installed, you can do so by running: install.packages("your.package.name"). After that, you will be able to load the package using library("the.package.you.just.installed"). See below the dependencies we will need for this workflow:

```{r libraries}
#| echo: true
#| output: false

library("tiff")           # opening geoTIFF files
library("raster")         # raster manipulation
library("sf")             # Simple Features vector data
library("ggplot2")        # plots
library("RColorBrewer")   # funky graph colors 
library("haven")          # opening stata files
library("gsubfn")         # string operations
library("viridis")        # colour palette for data visualisations
library("rgdal")          # RGDAL functions
library("sp")             # spatial objects in R
library("plyr")           # Data wrangling
library("dplyr")          # Data wrangling
library("readr")          # read rectangular data
library("leaflet")        # Interactive maps
library("htmlwidgets")              # HTML widgets
```

### Step 1 - Load all data sets

Our first step will simply be loading all the datasets that we will work with into our environment. The only step that the user needs to complete here is to specify the working directory where the .zip file "Geo-spatial Bangladesh data.zip" is saved (and unzipped). As a reminder, your folder structure should look like this after unzipping:

![](images/folder%20structure%20vol%202-02.png)

If this looks right, you are ready to run your first chunk of code below. This will load all the data we will need for this exercise into your environment. Whenever a .tif extension is used, we will import the file and convert it to a raster (recall this is the main format we will be working with). Some folders will have multiple files saved inside them (for example, there are three datasets from the Malaria Atlas Project). In this case, the code will pull all the files that have a .tif extension and save them in a list - so no need to import them individually!

```{r load layers}
#| echo: true
#| output: false

# Set working directory - this is the base folder where we keep all the sub-folders with geo-spatial data organised by source. 
setwd("C:/Users/idabr/OneDrive - Oxford Policy Management Limited/EMDI SAE/Geo-spatial Bangladesh data/")

# 1. Base layer #

# Load the WordPop Administrative Level 0 mastergrid base layer for Bangladesh 
base.layer <- 'Base layers/bgd_level0_100m_2000_2020.tif'
base.layer.raster=raster(base.layer)

# 2. Shapefile with boundaries of zones #

# Load the Shapefile with administrative level 3 (upazila in Bangladesh)
shapefile.zonal <- readOGR("Base layers/admin 3 level/bgd_admbnda_adm3_bbs_20201113.shp")

# Load the shapefile in a format that's nicer for plotting 
shapefile.zone.plot <- st_read("Base layers/admin 3 level/bgd_admbnda_adm3_bbs_20201113.shp")

# 3. Malaria Atlas accessibility datasets #

#Make a list of all TIFF files from the Malaria Atlas Project and import those into a list 
matlas.list <- list.files(path="Travel time - Malaria Atlas Project", pattern =".tiff", full.names=TRUE)

# Turn all files into a raster and make a list of rasters
matlas.rasters <- lapply(matlas.list, raster)

# 4. Demographic maps from Meta #

# Pull all TIFF files from Meta with demographic maps
fb.list <- list.files(path="Demographic maps Facebook/", pattern =".tif", full.names=TRUE)

# Turn all files into a raster and make a list of rasters
fb.rasters <- lapply(fb.list, raster)

# 5. Nightlights Data #

# Import geoTIFF file on nightlights intensity
nightlights <- 'Nightlights data/SVDNB_npp_20150101-20151231_75N060E_vcm-orm_v10_c201701311200.avg_rade9.tif'

# Turn into a raster 
nightlights.raster = raster(nightlights)

# 6. Pre-harmonised World Pop datasets #

# Make a list of all TIFF files from WorldPop and import those into a list 
worldpop.list <- list.files(path="World Pop Harmonised Datasets", pattern =".tif", full.names=TRUE)

# Turn all files into a raster and make a list of rasters
worldpop.rasters <- lapply(worldpop.list, raster)


```

You should now be able to view all the data in your environment. Most objects are of the class `RasterLayer`, which we discussed in Section 2.5.3. Let's have a closer look at how these objects are structured in practice and the information they contain by inspecting our base layer.

#### Check the attributes of the base layer

As we will be harmonising all other datasets to our base layer, it is important to understand its attributes. Simply typing the name of our base layer raster object in the console will provide information on: class, dimensions, resolution, extent, crs, source, and names. At the end of the workflow, all of our geo-spatial covariates will have the same spatial resolution, CRS, extent, and shape as our base layer.

```{r plot base raster}
# Check attributes associated with the base layer 
base.layer.raster

# Plot raster
plot(base.layer.raster, box=F, axes=F,legend=F, main = "Bangladesh base layer")
```

The output is telling us that our object of interest is a `RasterLayer`, with the following characteristics:

-   7272 rows, 5596 columns, and 40694112 cells altogether - these are the dimensions of our grid.

-   A spatial resolution of 0.0008333333 by 0.0008333333 (in degrees). This is equivalent to \~ 100m spatial resolution and defines the size of each cell in the raster.

-   Extent, i.e. the maximum and minimum values of longitude and latitude which define Bangladesh.

-   The WGS 1984 datum (EPSG: 4326) geographical projection - this is the most standard global projection.

-   It came from the GeoTIFF file named "bgd_level0_100m_2000_2020.tif" in our working directory and is named after that file.

We also produced our first map of Bangladesh! This is the raster layer we will be harmonising all our other data to. Note that since this layer simply gives us the administrative national boundaries of Bangladesh, it does not contain any data values. While most of our objects are raster data, we will use one vector dataset: a shapefile containing the boundaries of administrative level 3 (upazilas) in Bangladesh. There are multiple ways of storing vector data in R , as discusses in Section 2.5 - let's have a look.

#### Inspect the attributes of the shapefile with administrative level 3

Apart from the raster file defining the national boundaries of Bangladesh, we are interested to know the boundaries of the administrative zones that we will estimate poverty for. In our case, this is administrative level 3, or upazila, in Bangladesh. This information is provided by a shapefile, which is a *vector* dataset - and has different properties than raster data.

As before, we will start by simply typing the name of our spatial object into the console. This will provide information on: geometry, dimensions, extent, CRS, as well as give us a preview into the features. To demonstrate this, I saved our shapefile in two formats: 1) an `sf` object called `multipolygon`, and 2) a `sp` object called `SpatialPolygonsDataFrame`.

```{r}
# Inspect the sf multipolygon object with admin 3 boundaries
shapefile.zone.plot

# Inspect the sp SpatialPolygonsDataFrame object with admin 3 boundaries
shapefile.zonal

# Plot the shape file - this shows the zones for which we will estimate poverty
ggplot() + 
  geom_sf(data = shapefile.zone.plot, size = 3, color = "black", fill = "cyan1") + 
  ggtitle("Administrative Level 3 Bangladesh") + 
  coord_sf() + theme_minimal()
```

The output gives us the following information about the shape file:

-   It has 544 features (upazilas) and 16 fields (variables) with information defining the features.

-   The geometry type is multipolygon. Each multipolygon is a collection of spatial points that define an upazila.

-   Bounding box shows the extent, i.e. maximum and minimum values of longitude and latitude that define Bangladesh.

-   As in the case of our base layer, it uses the WGS 1984 datum (EPSG: 4326) geographical projection.

-   A preview of the first 10 features tells us that for each multipolygon we have information on: administrative codes for the upazila, English name of the upazila, area covered by the shape, and codes as well as names for other administrative levels.

The plot shows a visualisation of the boundaries of each upazila in Bangladesh. They are essentially a collection of multipolygons (i.e. each upazila is bound by a multipolygon object). We will be estimating poverty for each upazila. This illustrates our issue quite nicely - it would be prohibitively costly for a survey like the DHS to travel to each upazila and obtain a sufficient sample size to generate reliable poverty statistics. By using open-source high-resolution geo-spatial data, we can model poverty for each zone, including out-of-sample areas, i.e. areas where the DHS did not reach.

We now turn to Steps 2-5, which will process our raster layers of geo-spatial information.

### Steps 2-5 - Write functions for automated processing of geo-spatial covariates

Steps 2-5 all refer to the harmonisation of raster layers that conatin geo-spatial covariates. The goal is for all our datasets (accessibility, demographic maps, night lights) to have the same: extent, spatial resolution, and shape as the base layer. In some cases, we may need to additionally address missing values. A detailed description of Steps 2-5 can be found in Section 1.

The reason that all steps are grouped together into one section is that all of those will be performed in a single automated function. We will write two functions, one for accessibility and nightlights data and the second one for demographic maps from Facebook. The only difference between them is the algorithm used for changing the spatial resolution of rasters.

::: callout-caution
## Caution

There are many algorithms that can be used for changing the spatial resolution of a raster. For accessibility and nightlights data, we will use the nearest neighbour interpolation, where each "corrected" pixel is assigned a data value of the "uncorrected" pixel that is closest to it in terms of coordinate location. However, for harmonising demographic data that is of a higher spatial resolution than our base layer, the use of the "sum" algorithm is more appropriate. Otherwise we "lose people" in a downsample. To illustrate the issue, let's imagine we have 9 high resolution pixels (3x3). The sum algorithm will add up values from all those pixels when aggregating, while the nearest neighbour interpolation will select the value that falls closest to the "corrected" pixel, and not count any other ones.
:::

To automate the processing, we will write the first function for processing geo-spatial covariates and call it `geo_process`. We will use it for the Malaria Atlas accessibility and Nightlights data. It automatically executes the following steps:

1.  Crop your raster to the base layer so that they have the same extent.
2.  Change the spatial resolution of your raster to match that of the base layer using the nearest neighbor interpolation algorithm.
3.  If appropriate, recode missing values to a specified value.
4.  Mask the raster so that it has the same shape as your base layer.

The function requires the following inputs:

-   `aux.raster` - this is the raster that you are trying to transform/ harmonise to the base raster layer.

-   `base.raster` - your base raster layer that has all the desired attributes. This is the layer we will be harmonising to.

-   `label` - the name that you wish to assign to the transformed raster.

-   `value` - (if appropriate) the value to which you want to recode NA (missing) values to.

This process will output your transformed raster, ready to be used in the calculation of zonal statistics.

Running the chunk below will create the first function `geo_process`, which will show up under "Functions" in you environment.

```{r function ngb}
# Function for automating the processing of geo-spatial covariates for use in poverty modelling
geo_process <- function(aux.raster, base.raster, label, value) {

    # 1. Crop to the base layer so they have the same extent
    r <- crop(aux.raster, base.raster)

    # 2. Change resolution to the resolution of the base layer using nearest neighbour interpolation
    r <- resample(r, base.raster, method = "ngb") 
    
    # 3. Replace NA with a specified value (if appropriate)
    r[is.na(r[])] <- value  

    # 4. Select only the shape of Bangladesh as defined by the base layer
    r <- mask(x = r, mask = base.raster)
    
    # Assign a name to the raster
    names(r) <- label
    return(r)
    
}
```

The second function, called `geo_process2` is really similar, but applies the `sum` algorithm instead of nearest neighbour interpolation when changing the spatial resolution, which is the appropriate method when working with demographic maps from Meta that are of a higher resolution than our base layer. The demographic data from Meta are of a \~30m spatial resolution and require aggregation of the values in each cell when resampled to 100m. Using the nearest neighbour interpolation, we 'lose' people (because data is thrown away in the downsample). The'sum' algorithm instead provides a more accurate representation of population per each 100m grid cell.

Function 2 should be applied to all demographic maps from Meta and will execute the following steps:

1.  Obtain the ratio of spatial resolutions of your layer of interest (from Meta) and the base layer, save those as a `factor.ratio`.
2.  Crop your raster to the base layer so that they have the same extent.
3.  If appropriate, recode missing values to a specified value.
4.  Change the spatial resolution to match your base layer, on the basis of the ratio defined in Step 1. Note: we are going from a higher to a lower spatial resolution, hence the use of "aggregate".
5.  Mask the raster so that it has the same shape as your base layer.

Running the chunk below will create the second function `geo_process2` and it will show up under "Functions" in you environment.

```{r}
# Function for automating the processing of geo-spatial covariates for use in poverty modelling
geo_process2 <- function(aux.raster, base.raster, label, value) {
  
    # 1. Get spatial resolutions of both rasters 
    res1 <- res(base.raster)
    res2 <- res(aux.raster)
    
    # Save as a factor of ratios 
    factor.ratio <- res1/res2
    factor.ratio <- factor.ratio[[1]]

    # 2. Crop to the base layer so they have the same extent
    r <- crop(aux.raster, base.raster)
    
    # 3. Replace NA with a specified value (if appropriate)
    r[is.na(r[])] <- value  

    # 4. Change resolution to the resolution of the base layer using the "sum"        algorithm
    r <- aggregate(r, fact=factor.ratio, fun=sum, na.rm=TRUE)

    # 5. Select only the shape of Bangladesh as defined by the base layer
    r <- mask(x = r, mask = base.raster)
    
    # Assign a name to the raster
    names(r) <- label
    return(r)
    
}
```

Now that we have two automated functions for processing geo-spatial data: `geo_process` and `geo_process2`, we can apply it to our raster datasets and create our first visualisations!

### Steps 2-5 - process accessibility data from the Malaria Atlas

In the chunk below, we will process accessibility data from the Malaria Atlas. Those are stored in a list of rasters named `matlas.rasters`. Simply typing the name of the object tells us more information about each raster in the list, including its class, dimensions, resolution, extent, crs etc. There are three datasets we will be using:

1.  Travel Time to Cities for Bangladesh in 2015
2.  Motorised Travel Time to Healthcae Facilities for Bangladesh in 2020
3.  Walking Only Travel Time to Healthcare Facilities for Bangladesh in 2020.

We will create a new list to store our processed datasets called `matlas.processed`, then use a loop to apply our `geo_process` function to all three Malaria Atlas datasets.

```{r}
# See that all the files have loaded
matlas.rasters

# Now apply this function to a list of rasters from the Malaria Atlas 

# Make a list for storing the processed rasters 
matlas.processed <- list()

# Store the length of the list of rasters
num_r <- 1:length(matlas.rasters)  

# Apply the geo-processing function to all rasters. Here there is no need to replace missing values as 0s (they are already coded as missing), so the parameter for value can stay at NA.
for (i in num_r) { 
matlas.processed[[i]] <- geo_process(aux.raster = matlas.rasters[[i]], base.raster = base.layer.raster, label = matlas.rasters[[i]]@data@names, value = NA)

}

# See the result
matlas.processed

# Compare to base layer
base.layer.raster

```

Viewing the ready `matlas.processed` objects, we can see that the dimensions as well as the extent have changed - they are now the same as our base layer.

Now let's visualise our results! In the code chunk below, I'll present three ways of visualising geo-spatial layers of information in R:

1.  A simple plot
2.  A high-quality plot image (same as point 1 but manually changing R's default plot resolution to improve quality)
3.  An interactive html widget using the `leaflet` package

```{r}
# Three ways of visualising our data:

## 1. Simple plot ##

# Plot results - with no bounding box or axes, using the viridis colour palette, and adding a main plot title
plot(matlas.processed[[1]], box=F, axes=F, col=viridis(50), main = "Bangladesh - Travel Time to Cities")
plot(matlas.processed[[2]], box=F, axes=F, col=viridis(50), main = "Bangladesh - Motorised Travel Time to Healthcare Facilities")
plot(matlas.processed[[3]], box=F, axes=F, col=viridis(50), main = "Bangladesh - Walking-Only Travel Time to Healthcare Facilities")

## 2. A high-quality plot image ##

# Create a high quality image - manually changing the resolution of base R plots
png(filename="maps/BGD travel time city.png", res=400, width=2000, height=1500)
plot(matlas.processed[[1]], box=F, axes=F, col=viridis(50), main = "Bangladesh - Travel Time to Cities")
dev.off()

## 3. An interactive html widget ##

# First create a colour palette - let's go with viridis, and supply the values of our raster into domain
pal <- leaflet::colorNumeric(viridis_pal(option = "C")(2), domain = values(matlas.processed[[1]]), na.color = "transparent")

# Create an interactive leaflet map
map_access <- leaflet() %>%
 addProviderTiles(providers$CartoDB.Positron) %>%
  addRasterImage(matlas.processed[[1]],  colors = pal, opacity=0.9, project = FALSE)%>%
  addLegend(pal = pal, values = values(matlas.processed[[1]]), title = "Travel Time to Cities in Minutes")

# Let's have a look
map_access

# Save map as widget
saveWidget(map_access, file="html widgets/BGD_access_map.html")
```

Let's start with simple plots. The three plots show visualisations of travel time (in minutes) using the `viridis` colour palette. Coastal areas as well as western parts of the Chittagong division appear to be least connected to urban areas and healthcare facilities. While this is informative at first glance, a closer zoom in will typically appear quite pixelated. This is because R's default plot resolution is quite low for high-resolution geo-spatial data. We can change that manually.

In order to view this plot in higher quality, we need to change R's default plot resolution. The second option will export a higher-quality image of the map showing travel time to cities for Bangladesh and save it in the `maps` folder in your working directory. Unless you are cloning this repo from GitHub, in which case the folder will already be there, you may need to simply add a folder named `maps` in your working directory that you specified in Step 1. The high-quality image will be saved there. Now you can zoom into your image and retain much more of the original granularity of the data - but we can step up that visualisation further!

The final approach is creating an interactive map through the `leaflet` package and exporting it as an html widget. This produces the highest quality visualisation and also allows the end user to interact with our data (for instance, zoom into specific areas of Bangladesh). First, we need to create a colour palette object called `pal`. Depending on whether we are portraying continuous or categorical data, we will choose the option `colorNumeric` (for continuous) or `colorFactor` (for categorical). We then have to supply our colour palette of interest - in this case `viridis_pal` and define the values that should be assigned to colours, i.e. values of the first raster in the list of processed Malaria Artlas list of rasters `matlas.processed[[1]]`. Finally, we want NA values to appear transparent.

Once we created the colour pallete, we can start creating our interactive map object called `map_access`. This relies on Open Street Map base layers that form a sort of "background" on which we will overlay our accessibility data. I selected `addProviderTiles(providers$CartoDB.Positron)`, which is a nice light greay shaded OSM global map as the background. There are other options (such as colourful backgrounds) that you can explore. On top of that, I am overlaying the raster image with travel time to cities for Bangladesh. I select the colour palette object `pal` and `opacity=0.9`, which controls the transparency of my layer. As the layer already has a specified CRS, we do not reproject. Finally, we add a legend in the viridis colour palette and values of the Malaria Atlas layer. This interactive map is saved in the `html widgets` folder in my working directory. You can choose any location on your local machine to save this file.

### Steps 2-5 - process the demographic data from Meta

To process the demographic data from Meta, we will apply the second function geo_process2, which relies on the sum algorithm for resampling rather than nearest neighbour interpolation, as discussed before. As before, we will begin by typing the name of the objects that stores a list with all raster files from Meta, fb.rasters. This will allow us to view the properties of the following seven datasets for Bangladesh:

1.  Population Density - Children under 5
2.  Population Density - Elderly 60+
3.  Population Density - General
4.  Population Density - Men
5.  Population Density - Women
6.  Population Density - Women of Reproductive Age 15-49
7.  Population Density - Youth 15-24

Just a note that these datasets use population density per pixel as their unit of measurement. This time, we will be applying our second function `geo_process2`, which differs only by the type of algorithm that is used for resampling. Since we are working with *demographic* data of a higher spatial resolution than our base layer, we need to aggregate our data to a coarser grid and the use of the `sum` algorithm will ensure that we are counting all the populations from all higher resolution pixels. An important step here is replacing missing values with zeros, which is done by specifying the argument `value = 0` in the `geo_process2` function. From the documentation, we know that pixels which have been coded as missing in fact have no people in it, i.e. the population density is zero - so we can safely recode. However, the user should always check whether recoding missing values as zeros is appropriate.

As before, we create a list `fblist.processed`, where we will store all the harmonised rasters with demographic information, and apply a loop to process all the seven raster layers with population density for Bangladesh.

```{r}
# Check that all the files were picked up by this 
fb.rasters

# Make a list for storing the processed rasters 
fblist.processed <- list()

# Store the length of the list of rasters
num_fb <- 1:length(fb.rasters)  

# Apply the geo-processing function to all rasters. Here we need to recode missing values as 0s
for (i in num_fb) { 
fblist.processed[[i]] <- geo_process2(aux.raster = fb.rasters[[i]], base.raster = base.layer.raster, label = fb.rasters[[i]]@data@names, value = 0)

}

# See the result
fblist.processed

# Compare to base layer
base.layer.raster

# Plot results
plot(fblist.processed[[1]], box=F, axes=F, main = "Bangladesh - Population density (children under 5)")
plot(fblist.processed[[2]], box=F, axes=F, main = "Bangladesh - Population density (elderly 60+)")
plot(fblist.processed[[3]], box=F, axes=F, main = "Bangladesh - Population density (general)")
plot(fblist.processed[[4]], box=F, axes=F, main = "Bangladesh - Population density (men)")
plot(fblist.processed[[5]], box=F, axes=F, main = "Bangladesh - Population density (women)")
plot(fblist.processed[[6]], box=F, axes=F, main = "Bangladesh - Population density (women of reproductive age 15-49)")
plot(fblist.processed[[7]], box=F, axes=F, main = "Bangladesh - Population density (youth 15-24)")

# Create a high quality image 
png(filename="maps/BGD_pop_density_youth.png", res=400, width=2000, height=1500)
plot(fblist.processed[[7]], box=F, axes=F, main = "Bangladesh - Population density (youth 15-24)")
dev.off()
```

The output from simply typing `fb.processed` into your console should show you the attributes of harmonised rasters with demographic data from Meta. The dimensions, resolution, extent, CRS should all be the same as the base layer. In addition, we can see the range of minimum and maximum values for each population density raster.

Visualisations show the population density (per pixel) for 7 population groups for Bangladesh. In all cases, we can see that population density increases around urban areas, such as Dhaka or Chattogram.

### Steps 2-5 - Process nightlights data

The final dataset that requires harmonisation is the Nightlights Intensity raster from the VIIRS satellite. It contains codified values of radiance per pixel. We will follow the same procedure as with the Malaria Atlas datasets and simply apply our `geo_process` function. In this case, there is no need to recode missing values. The output, `nightlights.raster.processed` should again show dimensions, resolution, extent, CRS that are the same as the base layer. In addition, we can see the range of minimum and maximum values of nightlights intensity.

```{r}
# Apply the geo processing function
nightlights.raster.processed <- geo_process(aux.raster = nightlights.raster, base.raster = base.layer.raster, label = "Nightlights_data", value = 0)

# Check raster
nightlights.raster.processed

# Compare to base layer
base.layer.raster

# Plot raster 
plot(nightlights.raster.processed, axes=F, box=F, main = "Nightlights data in Bangladesh", col=cividis(50))

# Create a high quality image 
png(filename="maps/nightlights_BGD.png", res=400, width=2000, height=1500)
plot(nightlights.raster.processed, box=F, axes=F, main = "Nightlights data in Bangladesh", col=cividis(50))
dev.off()
```

The visualisation, though a little difficult to see in R's standard plot resolution, shows that urban areas such as Dhaka appear to have a higher radiance of nightlights.

### Steps 2-5 - Inspect pre-harmonised World Pop datasets

```{r}
# See that all the files have loaded
worldpop.rasters

#Plot examples of WorldPop datasets
plot(worldpop.rasters[[11]], box = F, axes = F, main = "Distance to the closest road Bangladesh", col=viridis(50))
```

### Step 6 - Convert shapefile to a raster

```{r}
# Copy admin unit codes to new column in upazila shapefile attributes, in the process removing Bangladesh prefix from the integer code
shapefile.zonal@data$adm3_integer <- substr(shapefile.zonal@data[["ADM3_PCODE"]], 3, 10)

# Turn into numeric
shapefile.zonal@data[["adm3_integer"]] <- as.numeric(shapefile.zonal@data[["adm3_integer"]])

# Convert upazila shapefile to raster using the integer admin unit code, maintaining extent and cell size of L0 base layer
## Set up a raster "template" to use in rasterize()
ext_base <-  extent(base.layer.raster)
ncol_base <- base.layer.raster@ncols
nrow_base <- base.layer.raster@nrows

xy <- abs(apply(as.matrix(bbox(ext_base)), 1, diff))
r <- raster(ext_base, ncol=ncol_base, nrow=nrow_base)

## Rasterize the shapefile
raster_admin3 <-rasterize(shapefile.zonal, r, field=shapefile.zonal$adm3_integer)

# Assign the same CRS as the base layer 
crs_base <- crs(base.layer.raster)
crs(raster_admin3) <- crs_base

# Plot to see if values have been assigned to the raster
plot(raster_admin3, box=F, axes=F, legend=F)


```

### Step 7 - Calculation of zonal statistics

```{r}
# Make a list with all the rasters 
full.raster.list <- c(matlas.processed, fblist.processed, worldpop.rasters, nightlights.raster.processed)

# Check rasters 
full.raster.list

# Create a raster stack
raster.stack <- stack(full.raster.list)

# Zonal statistics 

# Mean
zonal.stats.mean <- zonal(raster.stack, raster_admin3, fun='mean', digits=6, na.rm=TRUE)
zonal.stats.mean <- as.data.frame(zonal.stats.mean)
colnames_mean <- colnames(zonal.stats.mean)  # gather column names
colnames_mean <- paste(colnames_mean, "mean", sep="_")  # add identifier for mean
colnames_mean <- colnames_mean[2:28]  # exclude zone
colnames(zonal.stats.mean)[2:28] <- colnames_mean  # rename columns
 

# Min
zonal.stats.min <- zonal(raster.stack, raster_admin3, fun='min', digits=6, na.rm=TRUE)
zonal.stats.min <- as.data.frame(zonal.stats.min)
colnames_min <- colnames(zonal.stats.min)
colnames_min <- paste(colnames_min, "min", sep="_")
colnames(zonal.stats.min)[2:28] <- colnames_min[2:28]

# Max
zonal.stats.max <- zonal(raster.stack, raster_admin3, fun='max', digits=6, na.rm=TRUE)
zonal.stats.max <- as.data.frame(zonal.stats.max)
colnames_max <- colnames(zonal.stats.max)
colnames_max <- paste(colnames_max, "max", sep="_")
colnames(zonal.stats.max)[2:28] <- colnames_max[2:28]

# Sum
zonal.stats.sum <- zonal(raster.stack, raster_admin3, fun='sum', digits=6, na.rm=TRUE)
zonal.stats.sum <- as.data.frame(zonal.stats.sum)
colnames_sum <- colnames(zonal.stats.sum)
colnames_sum <- paste(colnames_sum, "sum", sep="_")
colnames(zonal.stats.sum)[2:28] <- colnames_sum[2:28]

# SD
zonal.stats.sd <- zonal(raster.stack, raster_admin3, fun='sd', digits=6, na.rm=TRUE)
zonal.stats.sd <- as.data.frame(zonal.stats.sd)
colnames_sd <- colnames(zonal.stats.sd)
colnames_sd <- paste(colnames_sd, "sd", sep="_")
colnames(zonal.stats.sd)[2:28] <- colnames_sd[2:28]

# Count
zonal.stats.count <- zonal(raster.stack, raster_admin3, fun='count', digits=6, na.rm=TRUE)
zonal.stats.count <- as.data.frame(zonal.stats.count)
colnames_count <- colnames(zonal.stats.count)
colnames_count <- paste(colnames_count, "count", sep="_")
colnames(zonal.stats.count)[2:28] <- colnames_count[2:28]

# Make a list of all dataframes that contain zonal statistics
l.df <- lapply(ls(pattern="zonal.stats"), function(x) get(x))

# Combine all zonal statistics into one data frame 
zonal.stats.all <- bind_cols(l.df)

# Delete repeated columns for zones - occurs every 28 variables 
zonal.stats.all = subset(zonal.stats.all, select = -c(29, 57, 85, 113, 141)) 

# Rename the colum with upazila codes
colnames(zonal.stats.all)[1] <- "upazila.code"

# Save file 
save(zonal.stats.all, file = "C:/Users/idabr/OneDrive - Oxford Policy Management Limited/EMDI SAE/Geo-spatial Bangladesh data/BGD.zonalstats.RData")
```

Save my Rdata

```{r}
# Save the RData file 
save.image("C:/Users/idabr/OneDrive - Oxford Policy Management Limited/EMDI SAE/Geo-spatial Bangladesh data/Quarto github workspace.RData")

```

## 4. Caveats, problems, things to look out for
